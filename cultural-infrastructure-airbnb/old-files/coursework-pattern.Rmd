---
title: "rMarkdown GIS Project"
author: "Vishal Kumar"
date: "06/12/2019"
output: html_document
---

## Import Libraries

```{r}

##Load all our data
library(sf)
library(tmap)
library(tmaptools)
library(plyr)
library(tidyverse)
library(pins)
library(spatstat)
library(sp)
library(rgeos)
library(maptools)
library(GISTools)
library(tmap)
library(geojson)
library(geojsonio)
library(tmaptools)
library(raster)

tmap_mode("plot")

```


## Week 6 - Analysing spatial patterns

# Load shapefiles


```{r}

#----the following code has been adapted from (MacLachlan & Dennett, 2019: Section 10.4.1)

#----use the pin function from the pins package to store the GIS London boundary .zip files from data.london
pin_london_GIS <- pin("https://data.london.gov.uk/download/statistical-gis-boundary-files-london/9ba8c833-6370-4b11-abdc-314aa020d5e0/statistical-gis-boundaries-london.zip")

#----grab the shape files for Borough, Ward and LSOA based on their string values and cache
s <- grepl("Borough|Ward_|LSOA_2011", pin_london_GIS) & grepl(".shp$", pin_london_GIS)

#----create a list for Borough, Ward and LSOA shape files
BoroughsWardsLSOA <- pin_london_GIS[s]

#----turn each element in the list into a SF file using the st_read function
BoroughsWardsLSOAsf <- lapply(BoroughsWardsLSOA, st_read)

BoroughsWardsLSOAsf <- lapply(BoroughsWardsLSOAsf, crs=27700, st_transform)

#----create a variable for LSOAs in London by selecting the third element in the list
londonLSOA <- BoroughsWardsLSOAsf[[3]]


#----use the pin function from the pins package to store the Inner and Outer London boundary .zip files from data.london
pin_inner_outer <- pin("https://data.london.gov.uk/download/inner-and-outer-london-boundaries-london-plan-consultation-2009/684e59f2-9208-4da1-bf67-d8dfeb72c047/lp-consultation-oct-2009-inner-outer-london-shp.zip")

i_o <- grepl("lp-consultation-oct-2009-inner-outer", pin_inner_outer) & grepl(".shp$", pin_inner_outer)

inner_outer <- pin_inner_outer[i_o]

inner_outerSF <- st_read(inner_outer)

st_transform(inner_outerSF, 27700)

names(inner_outerSF)[names(inner_outerSF) == 'Boundary'] <- 'InnerOuter'

londonLSOA <- st_join(londonLSOA, inner_outerSF, by = c("geometry" = "geometry"))

#londonLSOA <- londonLSOA[londonLSOA$InnerOuter == 'Inner London',]

londonLSOA_SP <- as(londonLSOA, "Spatial")

BNG = "+init=epsg:27700"

londonLSOA_SP <- spTransform(londonLSOA_SP,BNG)

```


```{r}


#----read in the five Cultural Infrastructure classifications from data.london as a dataframe
culture <- read.csv("https://raw.githubusercontent.com/vishalkumarlondon/CASA0005_coursework/master/data/all-cultural-infra-map-google-places.csv")

print(colSums(is.na(culture)))

#----only keep rows from the five Cultural Infrastructure classifications if the longitude cell is filled in (i.e. not Null)
culture <- culture[complete.cases(culture$longitude), ]

#----only keep rows from the five Cultural Infrastructure classifications if the rating cell is filled in (i.e. not Null)
culture <- culture[!is.na(as.numeric(as.character(culture$rating))),]

#----only keep rows from the five Cultural Infrastructure classifications if the rating cell is not 0
culture <- culture[culture$rating != 0, ]

#----turn each of the  five Cultural Infrastructure dataframes into spatial objects
culture <- st_as_sf(culture, coords = c("longitude", "latitude"),  crs = 4326)
culture <- st_transform(culture, 27700)

culture_SP <- as(culture, "Spatial")

#now set up an EPSG string to help set the projection 
BNG = "+init=epsg:27700"

culture_BNG <- spTransform(culture_SP, BNG)
culture_BNG <- remove.duplicates(culture_BNG)

culture_SUB <- culture_BNG[londonLSOA_SP,]

#check to see that they've been removed
tmap_mode("view")
tm_shape(londonLSOA_SP) + tm_polygons(col = NA, alpha = 0.5) + tm_shape(culture_SUB) + tm_dots(col = "blue")
```


```{r}

sort(table(culture$Cultural.Venue.Type), decreasing = TRUE)
```


```{r}

#joined <- st_join(londonLSOA, culture, by = c("geometry" = "geometry"))

#joined <- joined[!duplicated(joined[c("Cultural.Venue.Type", "site_name", "address1")]),]

#sort(table(joined$InnerOuter), decreasing = TRUE)
```



```{r}

# i=0
# for (type in 1:nrow(culture_SUB)){
#   i <- i+1
#   #all_list <- culture_SUB@data$Cultural.Venue[[i]]
#   #music_SUB <- culture_SUB[culture_SUB@data$"Cultural.Venue.Type"=="Music venues (all)",]
#   #all_sub <- list(culture_SUB[culture_SUB@data$"Cultural.Venue.Type"==i,])
#   # bufSpPolygons <- SpatialPolygons(list(bufPolygons))
#   # bufSpPolygonDf <-patialPolygonsDataFrame(bufSpPolygons,bufferedPoints@data[i,])
#   # ptsInBuffer <- which(!is.na(over(pointCloudSpdf,spPolygonDf)))
#   # 
#   # # I'm assuming `value` is the field name containing the point height
#   # localMax <- order(pointCloudSpdf@data$value[ptsInBuffer],decreasing=TRUE)[1]
#   # localMaxes[localMax] <- TRUE
# }

#all_list

pub_SUB <- culture_SUB[culture_SUB@data$"Cultural.Venue.Type"=="Pub",]

music_SUB <- culture_SUB[culture_SUB@data$"Cultural.Venue.Type"=="Music venues (all)",]

community_SUB <- culture_SUB[culture_SUB@data$"Cultural.Venue.Type"=="Community centres",]

archive_SUB <- culture_SUB[culture_SUB@data$"Cultural.Venue.Type"=="Archives",]

libraries_SUB <- culture_SUB[culture_SUB@data$"Cultural.Venue.Type"=="Libraries",]

thatres_SUB <- culture_SUB[culture_SUB@data$"Cultural.Venue.Type"=="Theatres",]

dance_rehersal_SUB <- culture_SUB[culture_SUB@data$"Cultural.Venue.Type"=="Dance rehearsal studios",]

galleries_SUB <- culture_SUB[culture_SUB@data$"Cultural.Venue.Type"=="Commercial galleries",]

dance_SUB <- culture_SUB[culture_SUB@data$"Cultural.Venue.Type"=="Dance performance venues",]

museums_SUB <- culture_SUB[culture_SUB@data$"Cultural.Venue.Type"=="Museums and public galleries",]

#music_SUB

tm_shape(londonLSOA_SP) + tm_polygons(col = NA, alpha = 0.5) + tm_shape(music_SUB) + tm_dots(col = "blue")


```


# Looks at Kernel Density

```{r}

#now set a window as the borough boundary
# <- as.owin(BoroughMap[BoroughMap@data$LAD11NM=="Camden",])

window <- as.owin(londonLSOA_SP)

#create a point pattern dataset
culture_SUB.ppp <- ppp(x=culture_SUB@coords[,1], y=culture_SUB@coords[,2],window=window)


```

```{r}

plot(density(culture_SUB.ppp, sigma = 200))
```

```{r}

ggplot(US_states_geoms$albers_revised) + 
  geom_sf(fill = brown, color = "black", size = 0.5/.pt) +
  coord_sf(datum = NA, expand = FALSE) +
  theme_dviz_map() +
  theme(
    #plot.background = element_rect(fill = "cornsilk")
  )
```




<!-- ```{r} -->

<!-- plot(density(musicSub.ppp, sigma = 200)) -->
<!-- ``` -->


<!-- ```{r} -->

<!-- plot(density(galleriesSub.ppp, sigma = 200)) -->
<!-- ``` -->


<!-- ```{r} -->

<!-- plot(density(museumsSub.ppp, sigma = 200)) -->
<!-- ``` -->


<!-- ```{r} -->

<!-- plot(density(danceSub.ppp, sigma = 200)) -->
<!-- ``` -->




Quadrant Analysis


```{r}

#First plot the points
plot(culture_SUB.ppp, pch=16, cex=0.5, main="Cultural Infrastructure in Inner London")

#now count the points in that fall in a 6 x 6 grid overlaid across the window

x <- quadratcount(culture_SUB.ppp, nx = 10,  ny = 10)

#, add=T, col="red")

# 
# plot(quadratcount(culture_SUB.ppp, 
#                   nx = 10, 
#                   ny = 10),
#      add=T,
#      col="red")


```


```{r}

#run the quadrat count
#Qcount<-data.frame(quadratcount(musicSub.ppp, nx = 10, ny = 10))

Qcount <- data.frame(x)

#put the results into a data frame
QCountTable <- data.frame(table(Qcount$Freq, exclude=NULL))

#view the data frame
#QCountTable

#we don't need the last row, so remove it
#QCountTable <- QCountTable[-nrow(QCountTable),]

class(QCountTable[,1])

#oops, looks like it's a factor, so we need to convert it to numeric
vect<- as.numeric(levels(QCountTable[,1]))
vect <- vect[1:59]
QCountTable[,1] <- vect

#calculate the total blue plaques (Var * Freq)
QCountTable$total <- QCountTable[,1]*QCountTable[,2]

#calculate mean
sums <- colSums(QCountTable[,-1])
#sums

#and now calculate our mean Poisson parameter (lambda)
lambda <- sums[2]/sums[1]

QCountTable$Pr <- ((lambda^QCountTable[,1])*exp(-lambda))/factorial(QCountTable[,1])

options(scipen = 999)

#now calculate the expected counts and save them to the table
QCountTable$Expected <- round(QCountTable$Pr * sums[1],0)

#QCountTable

QCountTable<-QCountTable %>% drop_na()

```

```{r}

#Compare the frequency distributions of the observed and expected point patterns
plot(c(1,50),c(0,10), type="n", xlab="Number of Music Venues (Red=Observed, Blue=Expected)", ylab="Frequency of Occurances")
points(QCountTable$Freq, col="Red", type="o", lwd=3)
points(QCountTable$Expected, col="Blue", type="o", lwd=3)

```


```{r}

teststats <- quadrat.test(culture_SUB.ppp, nx = 10, ny = 10)
teststats

plot(culture_SUB.ppp, pch=16, cex=0.5, main="Blue Plaques in Harrow")
plot(teststats, add=T, col = "red")

```


```{r}

#K <- Kest(culture_SUB.ppp, correction="border")
#L <- Lest(culture_SUB.ppp, correction="border")

G <- Gest(culture_SUB.ppp, correction="border")

plot(G)

```




```{r}

library(raster)
library(fpc)
library(plyr)

#first check the coordinate reference system of the spatial polygon:
crs(londonLSOA_SP)

#first extract the points from the spatial points data frame
culture_SUB_Points <- data.frame(culture_SUB@coords[,1:2])

#now run the dbscan analysis
db <- fpc::dbscan(culture_SUB_Points, eps = 250, MinPts = 12)

plot(x, col=db$cluster)
points(x[db$cluster==0,], pch = 3, col = "grey")
hullplot(x, db)

#now plot the results
plot(db, culture_SUB_Points, main = "DBSCAN Output", frame = F)
plot(londonLSOA_SP, add=T)

#if(!require(devtools)) install.packages("devtools")
#https://rpkgs.datanovia.com/factoextra/index.html
#devtools::install_github("kassambara/factoextra")
#library("factoextra")
#fviz_cluster(km.res, culture_SUB_Points, stand = FALSE, frame = FALSE, geom = "point")


```


```{r}

# used to find suitable eps value based on the knee in plot
# k is no of nearest neighbours used, use min points
library(dbscan)

dbscan::kNNdistplot(culture_SUB_Points, k =  4)
```


```{r}

library(ggplot2)

db
```


```{r}

db$cluster
```



DBSAN

```{r}
#We can now add this cluster membership info back into our dataframe

culture_SUB_Points$cluster <- db$cluster

#Next we are going to create some convex hull polygons to wrap around the points in our clusters. Use the ddply function in the plyr package to get the convex hull coordinates from the cluster groups in our dataframe

library(plyr)
chulls <- ddply(culture_SUB_Points, .(cluster), function(df) df[chull(df$coords.x1, df$coords.x2), ])

#As 0 isn’t actually a cluster (it’s all points that aren’t in a cluster) drop it from the dataframe
chulls <- subset(chulls, cluster>=1)

```


```{r}

dbplot <- ggplot(data=culture_SUB_Points, 
                 aes(coords.x1,coords.x2, colour=cluster, fill=cluster)) 

#add the points in
dbplot <- dbplot + geom_point()

#now the convex hulls
dbplot <- dbplot + geom_polygon(data = chulls, 
                                aes(coords.x1,coords.x2, group=cluster), 
                                alpha = 0.5) 

#now plot, setting the coordinates to scale correctly and as a black and white plot (just for the hell of it)...
dbplot + theme_bw() + coord_equal()
```






```{r}



###add a basemap First get the bbox in lat long for Harrow
latlong <- "+init=epsg:4326" 
BoroughWGS <-spTransform(londonLSOA_SP, CRS(latlong))
BoroughWGS@bbox


```

```{r}

#basemap<-openmap(c(51.5530613,-0.4040719),c(51.6405318,-0.2671556), zoom=NULL,"stamen-toner")

#install.packages("ggmap")
library(ggmap)
basemap <- get_stamenmap(bbox = c(left = -51.5530613,
                                bottom = -0.4040719,
                                right = 51.6405318,
                                top = -0.2671556),
          maptype = "terrain", 
          crop = FALSE,
          zoom = 12)

# convert the basemap to British National Grid - remember we created the 
# BNG object right at the beginning of the practical - it's an epsg string...
#basemap_bng<-openproj(basemap, projection=BNG)

```

```{r}

ggmap(basemap) + geom_point(data=culture_SUB_Points, 
                                   aes(coords.x1,coords.x2, 
                                       colour=cluster, fill=cluster)) + 
  geom_polygon(data = chulls, aes(coords.x1,coords.x2, group=cluster, fill=cluster), 
               alpha = 0.5)  
```






## Moran's I

```{r}

library(rgdal)
#read the ward data in

proj4string(londonLSOA_SP) <- CRS("+init=epsg:27700")

#have a look to check that everything looks OK..
tmap_mode("view")

culture_SP <- culture_BNG[londonLSOA_SP,]

tm_shape(londonLSOA_SP) + tm_polygons(col = NA, alpha = 0.5) + tm_shape(culture_SUB) + tm_dots(col = "blue")

res <- poly.counts(culture_SUB, londonLSOA_SP)

#and add this as a column in our spatialPolygonsDataframe
londonLSOA_SP@data$BluePlaqueCount <-res

#as the wards are of different sizes, perhaps best that we calculate a density
londonLSOA_SP@data$BlueDensity <- (londonLSOA_SP$BluePlaqueCount/poly.areas(londonLSOA_SP))

tm_shape(londonLSOA_SP) + tm_polygons("BlueDensity", style="jenks", palette="PuOr", midpoint=NA, title="Blue Plaque Density")

```



More


```{r}

install.packages('spdep')

library(spdep)

#First calculate the centroids of all Wards in London
coordsW <- coordinates(londonLSOA_SP)

plot(coordsW)


```



```{r}

#create a neighbours list
LWard_nb <- poly2nb(londonLSOA_SP, queen=T)
#LWard_nb <- poly2nb(LondonLSOA, queen=FALSE)

#plot them
plot(LWard_nb, coordinates(coordsW), col="red")

#add a map underneath
plot(londonLSOA_SP, add=T)


```


```{r}

#error Empty neighbour sets found keeps popping up when I use LSOAs rather than the Ward shape file
# I looked at this blog post and entered the zero.policy=T parameter to make sure the code works but the final output is not goo enough


#create a spatial weights object from these weights
Lward.lw <- nb2listw(LWard_nb, zero.policy=TRUE, style="C")
head(Lward.lw$neighbours)

Lward.lw$neighbours

I_LWard_Global_Density <- moran.test(londonLSOA_SP@data$BlueDensity, Lward.lw, zero.policy=T)
I_LWard_Global_Density

```



```{r}

C_LWard_Global_Density <- geary.test(londonLSOA_SP@data$BlueDensity, Lward.lw, zero.policy=T)
C_LWard_Global_Density


```



```{r}


G_LWard_Global_Density <- globalG.test(londonLSOA_SP@data$BlueDensity, Lward.lw, zero.policy=T)
G_LWard_Global_Density

```


```{r}

#use the localmoran function to generate I for each ward in the city
I_LWard_Local <- localmoran(londonLSOA_SP@data$BluePlaqueCount, Lward.lw)
I_LWard_Local_Density <- localmoran(londonLSOA_SP@data$BlueDensity, Lward.lw)
#what does the output (the localMoran object) look like?
head(I_LWard_Local_Density)
I_LWard_Local_Density


```

```{r}

londonLSOA_SP@data$BLocI <- I_LWard_Local[,1]
londonLSOA_SP@data$BLocIz <- I_LWard_Local[,4]
londonLSOA_SP@data$BLocIR <- I_LWard_Local_Density[,1]
londonLSOA_SP@data$BLocIRz <- I_LWard_Local_Density[,4]


```



```{r}

#install.packages("RColorBrewer")

library(RColorBrewer)

breaks1<-c(-1000,-2.58,-1.96,-1.65,1.65,1.96,2.58,1000)

MoranColours<- rev(brewer.pal(8, "RdGy"))

tm_shape(london) + tm_polygons("BLocIRz", style="fixed", breaks=breaks1, palette=MoranColours, midpoint=NA, title="Local Moran's I, Blue Plaques in London")

```


