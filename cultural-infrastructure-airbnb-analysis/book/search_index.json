[
["index.html", "Measuring the impact of cultural infrastructure on Airbnb listings in London Chapter 1 Abstract", " Measuring the impact of cultural infrastructure on Airbnb listings in London Vishal Kumar 2020-01-11 Chapter 1 Abstract This study uses cultural data science to measure the impact of cultural infrastructure on the supply and demand of Airbnb listings in London. Put the rest of the abstract here. Code by Andy, Adam, Fundementals of Data Visualization, have been very helpful and have been referenced thoroughly throughout. This is a sample book written in Markdown. You can use anything that Pandoc’s Markdown supports, e.g., a math equation \\(a^2 + b^2 = c^2\\). To compile this example to PDF, you need XeLaTeX. You are recommended to install TinyTeX (which includes XeLaTeX): https://yihui.name/tinytex/. "],
["intro.html", "Chapter 2 Introduction", " Chapter 2 Introduction You can label chapter and section titles using {#label} after them, e.g., we can reference Chapter 2. If you do not manually label them, there will be automatic labels anyway, e.g., Chapter ??. Figures and tables with captions will be placed in figure and table environments, respectively. par(mar = c(4, 4, .1, .1)) plot(pressure, type = &#39;b&#39;, pch = 19) Figure 2.1: Here is a nice figure! Reference a figure by its code chunk label with the fig: prefix, e.g., see Figure 2.1. Similarly, you can reference tables generated from knitr::kable(), e.g., see Table 2.1. knitr::kable( head(iris, 20), caption = &#39;Here is a nice table!&#39;, booktabs = TRUE ) Table 2.1: Here is a nice table! Sepal.Length Sepal.Width Petal.Length Petal.Width Species 5.1 3.5 1.4 0.2 setosa 4.9 3.0 1.4 0.2 setosa 4.7 3.2 1.3 0.2 setosa 4.6 3.1 1.5 0.2 setosa 5.0 3.6 1.4 0.2 setosa 5.4 3.9 1.7 0.4 setosa 4.6 3.4 1.4 0.3 setosa 5.0 3.4 1.5 0.2 setosa 4.4 2.9 1.4 0.2 setosa 4.9 3.1 1.5 0.1 setosa 5.4 3.7 1.5 0.2 setosa 4.8 3.4 1.6 0.2 setosa 4.8 3.0 1.4 0.1 setosa 4.3 3.0 1.1 0.1 setosa 5.8 4.0 1.2 0.2 setosa 5.7 4.4 1.5 0.4 setosa 5.4 3.9 1.3 0.4 setosa 5.1 3.5 1.4 0.3 setosa 5.7 3.8 1.7 0.3 setosa 5.1 3.8 1.5 0.3 setosa You can write citations, too. For example, we are using the bookdown package (Xie 2020) in this sample book, which was built on top of R Markdown and knitr (Xie 2015). References "],
["load-data.html", "Chapter 3 Load Data 3.1 Load packages 3.2 Download data 3.3 Join the data 3.4 Clean variables before analysis", " Chapter 3 Load Data 3.1 Load packages #----load all the libraries needed library(sf) library(plyr) library(pins) library(tidyverse) library(tidyr) library(sp) #library(spdep) options(scipen = 999) 3.2 Download data 1. Download Airbnb data I collected every Airbnb “listings.csv” file for London from the website Inside Airbnb (http://insideairbnb.com/get-the-data.html) for the years 2017 and 2018, concatinated them all together and put it here (github link) on this project’s GitHub repo. In total, there are 242,490 unqiue listings with 14 columns of attributes. None of that raw data has had any post processing. #----read in Airbnb London listings data from the project GitHub repo as a dataframe airbnb &lt;- read_csv(&quot;data/airbnb-london-2017-2018.csv&quot;) print(dim(airbnb)) ## [1] 242490 14 This study does not look at the temporal change in price - i.e. the price difference between 2017 to 2018 - as the dependent variable. Rather, it averages out the price for each unique listing (by id) between 2017 and 2018. By doing this, adjustments for natural fluctations - for instance, seasonality - are averaged out. Future research may study dive deeper into the differences in price across time and season. #----create a new dataframe by grouping the listings id and creating an average price column price_average &lt;- airbnb %&gt;% group_by(id) %&gt;% summarise(price = mean(price)) colnames(price_average) &lt;- c(&quot;id&quot;, &quot;price_average&quot;) #----join the new dataframe to the original Airbnb data to add a column for the average price per listing between 2017 and 2018 airbnb &lt;- inner_join(airbnb, price_average, by = c(&#39;id&#39;)) #----keep the original Airbnb data my making a `airbnb_old` dataframe airbnb_old &lt;- airbnb #----remove unnecessary columns and remove duplicate listing ids to leave unique listings with average price between 2017 and 2018 #airbnb &lt;- airbnb[, ! colnames(airbnb) %in% c(&quot;price&quot;, &quot;last_review&quot;, &quot;year&quot;, &quot;month&quot;, &quot;day&quot;)] airbnb &lt;- airbnb[, ! colnames(airbnb) %in% c(&quot;price&quot;)] airbnb &lt;- airbnb[!duplicated(airbnb[c(&quot;id&quot;)]),] #----turn Airbnb datafram into an sf airbnb &lt;- st_as_sf(airbnb, coords = c(&quot;longitude&quot;, &quot;latitude&quot;), crs = 4326) airbnb &lt;- st_transform(airbnb, 27700) At this stage, outliers in price are removed, this is because the average price for some listings went as high as £10,000. All listings that had an average price 2.58 times the mean were removed. Moreover, prices recorded as zero were also removed. #----calculate the mean, min and max and std of the Airbnb prices for the whole of London print(summary(airbnb$price_average)) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.0 45.0 80.0 100.8 125.0 9999.0 airbnb_price_mean &lt;- mean(airbnb$price_average) airbnb_price_std &lt;- sd(airbnb$price_average) airbnb_price_mad &lt;- mad(airbnb$price_average) #----then remove Airbnb where the price is two standard deviations away from the mean - i.e. outliers airbnb &lt;- subset(airbnb, price_average &lt; (airbnb_price_mean+(2.58*airbnb_price_std)) &amp; price_average &gt; (airbnb_price_mean-(2.58*airbnb_price_std))) #----then remove Airbnb where the price is zero airbnb &lt;- airbnb[airbnb$price_average != 0,] print(summary(airbnb$price_average)) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 5.00 45.00 79.00 93.08 120.00 397.00 #----calculate the mean, min and max and std of the Airbnb prices for the whole of London print(summary(airbnb$price_average)) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 5.00 45.00 79.00 93.08 120.00 397.00 airbnb_price_mean &lt;- mean(airbnb$price_average) airbnb_price_std &lt;- sd(airbnb$price_average) airbnb_price_mad &lt;- mad(airbnb$price_average) #----then remove Airbnb where the price is two standard deviations away from the mean - i.e. outliers airbnb &lt;- subset(airbnb, price_average &lt; (airbnb_price_mean+(2.58*airbnb_price_std)) &amp; price_average &gt; (airbnb_price_mean-(2.58*airbnb_price_std))) #----then remove Airbnb where the price is zero airbnb &lt;- airbnb[airbnb$price_average != 0,] print(summary(airbnb$price_average)) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 5.00 44.50 75.00 86.82 120.00 258.50 2. Download Cultural Infrastructure data I collected data for every cultural venue in London by borough from data.london.gov (https://data.london.gov.uk/dataset/cultural-infrastructure-map). Specifically, the “Cultural venues by London borough” zip file was downloaded and then all the files were concatinated. In total there were 10,003 cultural venues in London. This entire dataset was then passed to the Google Places API to calculate the average user rating and total number of reviews for each venue. The total run time to recieve a ratings and reviews took 90 minutes, which is why it was much more efficient to calculated these metrics outside of this R script. For more information on the Google Place API, please visit this link (X) 1,958 venues out of the 10,003 total did not possess any, or had zero, user ratings and reviews on Google Places and were therefore dropped leaving 8,045 venues remaining for the analysis. #----read in the Cultural Infrastructure data from porject GitHubb culture &lt;- read.csv(&quot;data/all-cultural-infra-map-google-places.csv&quot;) print(dim(culture)) ## [1] 10003 25 print(colSums(is.na(culture))) ## BOROUGH Cultural.Venue.Type site_name address1 ## 0 0 0 0 ## address2 address3 borough_code borough_name ## 0 0 0 0 ## latitude longitude easting northing ## 0 0 0 0 ## os_addressbase_uprn ward_2018_code ward_2018_name website ## 4273 0 0 0 ## gss_code runtime API_response formatted_address ## 0 0 0 0 ## name place_id rating types ## 0 0 1556 0 ## user_ratings_total ## 1556 print(dim(culture[culture$rating == 0, ])) ## [1] 1958 25 #----only keep rows from Cultural Infrastructure if the longitude cell is filled in (i.e. not Null) culture &lt;- culture[complete.cases(culture$longitude), ] #----only keep rows from Cultural Infrastructure if the rating cell is filled in (i.e. not Null) culture &lt;- culture[!is.na(as.numeric(as.character(culture$rating))),] #----only keep rows from Cultural Infrastructure if the rating cell is not 0 culture &lt;- culture[culture$rating != 0, ] #----turn the Cultural Infrastructure dataframe into an sf object culture &lt;- st_as_sf(culture, coords = c(&quot;longitude&quot;, &quot;latitude&quot;), crs = 4326) culture &lt;- st_transform(culture, 27700) #culture_withPubs &lt;- culture #culture &lt;- culture[!culture$Cultural.Venue.Type == &#39;Pubs&#39;,] 3. Download London shapefile data The GIS shapefile boundaries for London were downloaded from data.london (https://data.london.gov.uk/dataset/statistical-gis-boundary-files-london). This research is interested in studying the Lower Super Output Area (LSOA) 2011 boundary area, however, Ward and Borough level shape files were also stored in a list if necessary. In total there are 4,835 LSOA areas. #----the following code has been adapted from (MacLachlan &amp; Dennett, 2019: Section 10.4.1) #----use the pin function from the pins package to store the GIS London boundary .zip files from data.london pin_london_GIS &lt;- pin(&quot;https://data.london.gov.uk/download/statistical-gis-boundary-files-london/9ba8c833-6370-4b11-abdc-314aa020d5e0/statistical-gis-boundaries-london.zip&quot;) #----grab the shape files for Borough, Ward and LSOA based on their string values and cache s &lt;- grepl(&quot;Borough|Ward_|LSOA_2011&quot;, pin_london_GIS) &amp; grepl(&quot;.shp$&quot;, pin_london_GIS) #----create a list for Borough, Ward and LSOA shape files BoroughsWardsLSOA &lt;- pin_london_GIS[s] #----turn each element in the list into a SF file using the st_read function BoroughsWardsLSOAsf &lt;- lapply(BoroughsWardsLSOA, st_read) ## Reading layer `London_Borough_Excluding_MHW&#39; from data source `/Users/vishalkumar.london/Library/Caches/pins/local/statistical_gis_boundaries_london/statistical-gis-boundaries-london/ESRI/London_Borough_Excluding_MHW.shp&#39; using driver `ESRI Shapefile&#39; ## Simple feature collection with 33 features and 7 fields ## geometry type: MULTIPOLYGON ## dimension: XY ## bbox: xmin: 503568.2 ymin: 155850.8 xmax: 561957.5 ymax: 200933.9 ## epsg (SRID): 27700 ## proj4string: +proj=tmerc +lat_0=49 +lon_0=-2 +k=0.9996012717 +x_0=400000 +y_0=-100000 +ellps=airy +towgs84=446.448,-125.157,542.06,0.15,0.247,0.842,-20.489 +units=m +no_defs ## Reading layer `London_Ward_CityMerged&#39; from data source `/Users/vishalkumar.london/Library/Caches/pins/local/statistical_gis_boundaries_london/statistical-gis-boundaries-london/ESRI/London_Ward_CityMerged.shp&#39; using driver `ESRI Shapefile&#39; ## Simple feature collection with 625 features and 7 fields ## geometry type: POLYGON ## dimension: XY ## bbox: xmin: 503568.2 ymin: 155850.8 xmax: 561957.5 ymax: 200933.9 ## epsg (SRID): 27700 ## proj4string: +proj=tmerc +lat_0=49 +lon_0=-2 +k=0.9996012717 +x_0=400000 +y_0=-100000 +ellps=airy +towgs84=446.448,-125.157,542.06,0.15,0.247,0.842,-20.489 +units=m +no_defs ## Reading layer `LSOA_2011_London_gen_MHW&#39; from data source `/Users/vishalkumar.london/Library/Caches/pins/local/statistical_gis_boundaries_london/statistical-gis-boundaries-london/ESRI/LSOA_2011_London_gen_MHW.shp&#39; using driver `ESRI Shapefile&#39; ## Simple feature collection with 4835 features and 14 fields ## geometry type: MULTIPOLYGON ## dimension: XY ## bbox: xmin: 503574.2 ymin: 155850.8 xmax: 561956.7 ymax: 200933.6 ## epsg (SRID): 27700 ## proj4string: +proj=tmerc +lat_0=49 +lon_0=-2 +k=0.9996012717 +x_0=400000 +y_0=-100000 +ellps=airy +towgs84=446.448,-125.157,542.06,0.15,0.247,0.842,-20.489 +units=m +no_defs BoroughsWardsLSOAsf &lt;- lapply(BoroughsWardsLSOAsf, crs=27700, st_transform) #----create a variable for LSOAs in London by selecting the third element in the list londonLSOA &lt;- BoroughsWardsLSOAsf[[3]] londonWard &lt;- BoroughsWardsLSOAsf[[2]] londonBorough &lt;- BoroughsWardsLSOAsf[[1]] 4. Download the LSOA profile data The LSOA atlas (https://data.london.gov.uk/dataset/lsoa-atlas) provides a summary of demographic and related data for each Lower Super Output Area in Greater London. Some of this attribbute data for each LSOA will be useful as independent variable later in the analysis. This data is downloaded from data.london and subset by 15 columns which are most relevant as per Dudas et al’s (2017) paper. #----run the code below if you want to read in LSOA attribute data using the current 2011 boundaries #----NOTE: There is comparatively less data for the new boundaries compared with the old boundaries londonLSOAProfiles &lt;- read_csv(&quot;https://data.london.gov.uk/download/lsoa-atlas/0193f884-2ccd-49c2-968e-28aa3b1c480d/lsoa-data.csv&quot;, na = c(&quot;&quot;, &quot;NA&quot;, &quot;n/a&quot;), locale = locale(encoding = &#39;Latin1&#39;), col_names = TRUE) ## Warning: 2 parsing failures. ## row col expected actual file ## 1348 House Prices;Median Price (£);2014 a double . &#39;https://data.london.gov.uk/download/lsoa-atlas/0193f884-2ccd-49c2-968e-28aa3b1c480d/lsoa-data.csv&#39; ## 2873 House Prices;Median Price (£);2014 a double . &#39;https://data.london.gov.uk/download/lsoa-atlas/0193f884-2ccd-49c2-968e-28aa3b1c480d/lsoa-data.csv&#39; select.me &lt;- c(&#39;Lower Super Output Area&#39;, &#39;Population Density;Area (Hectares);&#39;, &#39;Population Density;Persons per hectare;2013&#39;, &#39;Ethnic Group;BAME (%);2011&#39;, &#39;Country of Birth;% Not United Kingdom;2011&#39;, &#39;Tenure;Owned outright (%);2011&#39;, &#39;Tenure;Owned with a mortgage or loan (%);2011&#39;, &#39;House Prices;Median Price (£);2014&#39;, &#39;Economic Activity;Employment Rate;2011&#39;, &#39;Qualifications;% Highest level of qualification: Level 4 qualifications and above;2011&#39;, &#39;Household Income, 2011/12;Median Annual Household Income estimate (£)&#39;, &#39;Public Transport Accessibility Levels (2014);% 4-6 (good access)&#39;, &#39;2013 Census Population;Age Structure;16-29&#39;, &#39;2014 Census Population;Age Structure;30-44&#39;, &#39;Dwelling type;All Households;2011&#39;) londonLSOAProfiles &lt;- londonLSOAProfiles[,select.me] 5. Download Inner/Outer London boundaries It will be useful to compare Airbnb lisitings and cultural infrastructure in Inner London vs Outer London as it is likely that the freqncy, price and average ratings of the former will all be higher than the later. Download the Inner/Outer London boundaries from data.london #----use the pin function from the pins package to store the Inner and Outer London boundary .zip files from data.london pin_inner_outer &lt;- pin(&quot;https://data.london.gov.uk/download/inner-and-outer-london-boundaries-london-plan-consultation-2009/684e59f2-9208-4da1-bf67-d8dfeb72c047/lp-consultation-oct-2009-inner-outer-london-shp.zip&quot;) #----pull out the Inner and Outer London shapefile i_o &lt;- grepl(&quot;lp-consultation-oct-2009-inner-outer&quot;, pin_inner_outer) &amp; grepl(&quot;.shp$&quot;, pin_inner_outer) #----create a list for the shape file inner_outer &lt;- pin_inner_outer[i_o] #----turn the shapefile into a SF file using the st_read function inner_outerSF &lt;- st_read(inner_outer) ## Reading layer `lp-consultation-oct-2009-inner-outer-london&#39; from data source `/Users/vishalkumar.london/Library/Caches/pins/local/lp_consultation_oct_2009_inner_outer_london_shp/lp-consultation-oct-2009-inner-outer-london.shp&#39; using driver `ESRI Shapefile&#39; ## Simple feature collection with 2 features and 5 fields ## geometry type: POLYGON ## dimension: XY ## bbox: xmin: 503568.2 ymin: 155850.8 xmax: 561957.5 ymax: 200933.9 ## epsg (SRID): 27700 ## proj4string: +proj=tmerc +lat_0=49 +lon_0=-2 +k=0.9996012717 +x_0=400000 +y_0=-100000 +ellps=airy +towgs84=446.448,-125.157,542.06,0.15,0.247,0.842,-20.489 +units=m +no_defs st_transform(inner_outerSF, 27700) ## Simple feature collection with 2 features and 5 fields ## geometry type: POLYGON ## dimension: XY ## bbox: xmin: 503568.2 ymin: 155850.8 xmax: 561957.5 ymax: 200933.9 ## epsg (SRID): 27700 ## proj4string: +proj=tmerc +lat_0=49 +lon_0=-2 +k=0.9996012717 +x_0=400000 +y_0=-100000 +ellps=airy +towgs84=446.448,-125.157,542.06,0.15,0.247,0.842,-20.489 +units=m +no_defs ## Boundary Source Area_Ha Shape_Leng Shape_Area ## 1 Inner London London Plan Consultation Draft 34863.3 117020.7 348632957 ## 2 Outer London London Plan Consultation Draft 124606.8 373367.7 1246068121 ## geometry ## 1 POLYGON ((522055.6 178014.7... ## 2 POLYGON ((503611.2 175520.4... 3.3 Join the data 1. Join Airbnb data with LSOA shapefile The functions below join the Airbnb data to the LSOA areas in London and a) count the number of Airbnb listings per LSOA, b) calculating the average price of Airbnb lisitngs per LSOA, c) counting the number of Airbnb user reviews per LSOA, and d) calculating the average number of Airbnb user reviews per LSOA. JoinAirbnb_count &lt;- function(data1, data2) { #----join dataframes joined &lt;- st_join(data1, data2, join = st_within) #----count the number of points per LSOA count &lt;- as.data.frame(plyr::count(joined$LSOA11CD)) names(count) &lt;- c(&quot;LSOA11CD&quot;, &quot;airbnb_freq&quot;) return(count) } JoinAirbnb_price &lt;- function(data1, data2) { #----join dataframes joined &lt;- st_join(data1, data2, join = st_within) #----calculate the average price of Airbnb per LSOA price &lt;- aggregate(price_average~LSOA11CD, joined, mean) names(price) &lt;- c(&quot;LSOA11CD&quot;, &quot;airbnb_price&quot;) return(price) } JoinAirbnb_NOreviews &lt;- function(data1, data2) { #----join dataframes joined &lt;- st_join(data1, data2, join = st_within) #----calculate the average price of Airbnb per LSOA reviews &lt;- aggregate(number_of_reviews~LSOA11CD, joined, sum) names(reviews) &lt;- c(&quot;LSOA11CD&quot;, &quot;airbnb_no_reviews&quot;) return(reviews) } JoinAirbnb_AVreviews &lt;- function(data1, data2) { #----join dataframes joined &lt;- st_join(data1, data2, join = st_within) #----calculate the average price of Airbnb per LSOA reviews &lt;- aggregate(number_of_reviews~LSOA11CD, joined, mean) names(reviews) &lt;- c(&quot;LSOA11CD&quot;, &quot;airbnb_av_reviews&quot;) return(reviews) } #----//////////////////////////////////////////////////////////////////////// #----AIRBNB COUNT----# #----use the first function to count the number of Airbnbs in each LSOA airbnbLSOA_count &lt;- JoinAirbnb_count(airbnb, londonLSOA) #----AIRBNB PRICE----# #----use the second function to calculate the average price of Airbnb listings in each LSOA airbnbLSOA_price &lt;- JoinAirbnb_price(airbnb, londonLSOA) #----AIRBNB NUMBER OF REVIEWS----# #----use the third function to count the number of Airbnb reviews in each LSOA airbnbLSOA_review_count &lt;- JoinAirbnb_NOreviews(airbnb, londonLSOA) #----AIRBNB AVERAGE NUMBER OF REVIEWS----# #----use the fourth function to calculate the average number of Airbnb reviews in each LSOA airbnbLSOA_review_average &lt;- JoinAirbnb_AVreviews(airbnb, londonLSOA) 2. Join Culture data with LSOA shapefile The functions below join the Cultural Infrastructure data to the LSOA areas in London and a) count the number of Cultural Infrastructure by cultural venue type per LSOA, b) calculating the average Google Places user rating by cultural venue type per LSOA, c) calculating the average number of Google Places user reviews by cultural venue type per LSOA, and d) counting the total number of Google Places user reviews by cultural venue type per LSOA. JoinCulture_count &lt;- function(data1, data2) { #----join dataframes joined &lt;- st_join(data1, data2, join = st_within) #----count the number cultural venue types per LSOA #source----https://stackoverflow.com/questions/10879551/frequency-count-of-two-column-in-r count &lt;- ddply(joined, .(joined$LSOA11CD, joined$Cultural.Venue.Type), nrow) names(count) &lt;- c(&quot;LSOA11CD&quot;, &quot;cultural_venue_type&quot;, &quot;culture_freq&quot;) #----then use the spread function from the tidyr lib to turn long data into wide data - i.e. a column for each cultural venue type #source----https://uc-r.github.io/tidyr count &lt;- count %&gt;% spread(cultural_venue_type, culture_freq) #----then use the rowSums function to sum up the counts from all cultural venue type, skip NA values and create new column count$culture_freq &lt;- rowSums(count[,sapply(count, is.numeric)], na.rm=TRUE) return(count) } JoinCulture_rating &lt;- function(data1, data2) { #----join dataframes joined &lt;- st_join(data1, data2, join = st_within) #----calculate the average rating of cultural venue types per LSOA #https://stackoverflow.com/questions/11562656/calculate-the-mean-by-group average &lt;- ddply(joined, .(joined$LSOA11CD, joined$Cultural.Venue.Type), function(x) mean(x$rating)) names(average) &lt;- c(&quot;LSOA11CD&quot;, &quot;cultural_venue_type&quot;, &quot;culture_rating&quot;) #----then use the spread function from the tidyr lib to turn long data into wide data - i.e. a column for each cultural venue type #source----https://uc-r.github.io/tidyr average &lt;- average %&gt;% spread(cultural_venue_type, culture_rating) #----then use the rowSums function to average the ratings from all cultural venue type, skip NA values and create new column average$culture_rating &lt;- rowMeans(average[,sapply(average, is.numeric)], na.rm=TRUE) return(average) } JoinCulture_NOreviews &lt;- function(data1, data2) { #----join dataframes joined &lt;- st_join(data1, data2, join = st_within) #----calculate the sum of reviews of cultural venue types per LSOA #https://stackoverflow.com/questions/11562656/calculate-the-mean-by-group count &lt;- ddply(joined, .(joined$LSOA11CD, joined$Cultural.Venue.Type), function(x) sum(x$user_ratings_total)) names(count) &lt;- c(&quot;LSOA11CD&quot;, &quot;cultural_venue_type&quot;, &quot;culture_no_reviews&quot;) #----then use the spread function from the tidyr lib to turn long data into wide data - i.e. a column for each cultural venue type #source----https://uc-r.github.io/tidyr count &lt;- count %&gt;% spread(cultural_venue_type, culture_no_reviews) #----then use the rowSums function to sum up the reviews from all cultural venue type, skip NA values and create new column count$culture_no_reviews &lt;- rowSums(count[,sapply(count, is.numeric)], na.rm=TRUE) return(count) } JoinCulture_AVreviews &lt;- function(data1, data2) { #----join dataframes joined &lt;- st_join(data1, data2, join = st_within) #----calculate the average rating of cultural venue types per LSOA #https://stackoverflow.com/questions/11562656/calculate-the-mean-by-group average &lt;- ddply(joined, .(joined$LSOA11CD, joined$Cultural.Venue.Type), function(x) mean(x$user_ratings_total)) names(average) &lt;- c(&quot;LSOA11CD&quot;, &quot;cultural_venue_type&quot;, &quot;culture_av_reviews&quot;) #----then use the spread function from the tidyr lib to turn long data into wide data - i.e. a column for each cultural venue type #source----https://uc-r.github.io/tidyr average &lt;- average %&gt;% spread(cultural_venue_type, culture_av_reviews) #----then use the rowSums function to average the reviews from all cultural venue type, skip NA values and create new column average$culture_av_reviews &lt;- rowMeans(average[,sapply(average, is.numeric)], na.rm=TRUE) return(average) } #----//////////////////////////////////////////////////////////////////////// #----CULTURE COUNT----# #----use the first function to count the number for each cultural venue category in each LSOA cultureLSOA_count &lt;- JoinCulture_count(culture, londonLSOA) #----CULTURE RATING----# #----use the second function to calculate the average rating of Google Places reviews for each cultural venue category in each LSOA cultureLSOA_rating &lt;- JoinCulture_rating(culture, londonLSOA) #----CULTURE NUMBER OF REVIEWS----# #----use the third function to count the number of Google Places reviews for each cultural venue category in each LSOA cultureLSOA_review_count &lt;- JoinCulture_NOreviews(culture, londonLSOA) #----CULTURE AVERAGE NUMBER OF REVIEWS----# #----use the third function to count the number of Google Places reviews for each cultural venue category in each LSOA cultureLSOA_review_average &lt;- JoinCulture_AVreviews(culture, londonLSOA) 3. Join Airbnb, Culture and LSOA shapefile data Having done the previous calculations for Airbnb and Cultural Infrastructure per LSOA, all the data is joined together. #----merge all dataframes into one #https://stackoverflow.com/questions/8091303/simultaneously-merge-multiple-data-frames-in-a-list #install safejoin package from GitHub devtools::install_github(&quot;moodymudskipper/safejoin&quot;) library(safejoin) #----use eat function from safejoin to merge a list of all the dataframes londonLSOAextradata &lt;- eat(airbnbLSOA_count, list(airbnbLSOA_price, airbnbLSOA_review_count, airbnbLSOA_review_average, cultureLSOA_count, cultureLSOA_rating, cultureLSOA_review_count, cultureLSOA_review_average), .by = &quot;LSOA11CD&quot;, .conflict = ~.x) 4. Join LSOA profile data to the rest Now that we have all of our data, we join them all together to create the londonLSOAProfiles sf object. Moreover, we caclulate the frequency density of cultural venue type per km^2 in every LSAO as per #----merge the LSOA boundaries shapefile with the and LSOA attribute dataframe londonLSOAProfiles &lt;- inner_join(londonLSOA, londonLSOAProfiles, by = c(&quot;LSOA11CD&quot; = &quot;Lower Super Output Area&quot;)) ## Warning: Column `LSOA11CD`/`Lower Super Output Area` joining factor and ## character vector, coercing into character vector #londonLSOAProfiles &lt;- na.omit(londonLSOAProfiles) #----join the extra data - Airbnb price &amp; counts and culture counts - to the LSAO profile data londonLSOAProfiles &lt;- inner_join(londonLSOAProfiles, londonLSOAextradata, by = c(&#39;LSOA11CD&#39;)) ## Warning: Column `LSOA11CD` joining character vector and factor, coercing into ## character vector 5. Join Inner/Outer London boundaries with the data Inner/Outer London boundaries join with dataset. #----join the shapefile to the LSOA SF obbject on geometry inner_outer_df &lt;- st_join(londonLSOA, inner_outerSF, by = c(&quot;geometry&quot; = &quot;geometry&quot;)) inner_outer_df &lt;- as.data.frame(inner_outer_df) names(inner_outer_df)[names(inner_outer_df) == &#39;Boundary&#39;] &lt;- &#39;InnerOuter&#39; select.me &lt;- c(&#39;LSOA11CD&#39;,&#39;InnerOuter&#39;) inner_outer_df &lt;- inner_outer_df[,select.me] #----join the Inner and Outer London extra data to the LSAO profile data londonLSOAProfiles &lt;- inner_join(londonLSOAProfiles, inner_outer_df, by = c(&quot;LSOA11CD&quot; = &quot;LSOA11CD&quot;)) ## Warning: Column `LSOA11CD` joining character vector and factor, coercing into ## character vector #----drop duplicate rows for LSOA11CD, culture_freq, airbnb_price, airbnb_freq columns londonLSOAProfiles &lt;- londonLSOAProfiles[!duplicated(londonLSOAProfiles[c(&quot;LSOA11CD&quot;, &quot;culture_freq&quot;, &quot;airbnb_price&quot;, &quot;airbnb_freq&quot;)]),] #londonLSOAProfiles &lt;- londonLSOAProfiles[londonLSOAProfiles$InnerOuter == &#39;Inner London&#39;,] 3.4 Clean variables before analysis Some variable names are changed before the analysis for ease of use and also to align with Dudas et al (2017). #----change the column names of some of the independent variables colnames(londonLSOAProfiles)[which(names(londonLSOAProfiles) == &quot;Population Density;Area (Hectares);&quot;)] &lt;- &quot;areaLSOA&quot; colnames(londonLSOAProfiles)[which(names(londonLSOAProfiles) == &quot;Population Density;Persons per hectare;2013&quot;)] &lt;- &quot;pop_density&quot; colnames(londonLSOAProfiles)[which(names(londonLSOAProfiles) == &quot;Ethnic Group;BAME (%);2011&quot;)] &lt;- &quot;bame_p&quot; colnames(londonLSOAProfiles)[which(names(londonLSOAProfiles) == &quot;Country of Birth;% Not United Kingdom;2011&quot;)] &lt;- &quot;nonUK&quot; colnames(londonLSOAProfiles)[which(names(londonLSOAProfiles) == &quot;Tenure;Owned outright (%);2011&quot;)] &lt;- &quot;house_own&quot; colnames(londonLSOAProfiles)[which(names(londonLSOAProfiles) == &quot;Tenure;Owned with a mortgage or loan (%);2011&quot;)] &lt;- &quot;house_mortg&quot; colnames(londonLSOAProfiles)[which(names(londonLSOAProfiles) == &quot;House Prices;Median Price (£);2014&quot;)] &lt;- &quot;house_price&quot; colnames(londonLSOAProfiles)[which(names(londonLSOAProfiles) == &quot;Economic Activity;Employment Rate;2011&quot;)] &lt;- &quot;employees&quot; colnames(londonLSOAProfiles)[which(names(londonLSOAProfiles) == &quot;Qualifications;% Highest level of qualification: Level 4 qualifications and above;2011&quot;)] &lt;- &quot;education&quot; colnames(londonLSOAProfiles)[which(names(londonLSOAProfiles) == &quot;Household Income, 2011/12;Median Annual Household Income estimate (£)&quot;)] &lt;- &quot;income&quot; colnames(londonLSOAProfiles)[which(names(londonLSOAProfiles) == &quot;Public Transport Accessibility Levels (2014);% 4-6 (good access)&quot;)] &lt;- &quot;transport&quot; colnames(londonLSOAProfiles)[which(names(londonLSOAProfiles) == &quot;2013 Census Population;Age Structure;16-29&quot;)] &lt;- &quot;age16_29&quot; colnames(londonLSOAProfiles)[which(names(londonLSOAProfiles) == &quot;2014 Census Population;Age Structure;30-44&quot;)] &lt;- &quot;age30_44&quot; colnames(londonLSOAProfiles)[which(names(londonLSOAProfiles) == &quot;Dwelling type;All Households;2011&quot;)] &lt;- &quot;housing&quot; #----change the some of the independent variables to density values by dividing by the area of the LSOA in hectares - areaLSOA londonLSOAProfiles$young_p &lt;- ((londonLSOAProfiles$age16_29 + londonLSOAProfiles$age30_44)/londonLSOAProfiles$areaLSOA)*100 londonLSOAProfiles$housing &lt;- (londonLSOAProfiles$housing/londonLSOAProfiles$areaLSOA)*100 #----calculate the km^2 frequency density of Airbnb per LSAO (as per Dudas et al, 2017) londonLSOAProfiles$airbnb_freq &lt;- (londonLSOAProfiles$airbnb_freq/londonLSOAProfiles$areaLSOA)*100 londonLSOAProfiles$airbnb_no_reviews &lt;- (londonLSOAProfiles$airbnb_no_reviews/londonLSOAProfiles$areaLSOA)*100 #----find the column numbers for first and last cultural venue type which( colnames(londonLSOAProfiles)==&quot;Archives&quot; ) ## [1] 33 which( colnames(londonLSOAProfiles)==&quot;culture_freq&quot; ) ## [1] 66 #----function to change variable from freqency to freqency density per km2 by dividing by the LSOA hectare size and muliplying by 100 A &lt;- function(x) (x / londonLSOAProfiles$`areaLSOA`)*100 #----calculate the km^2 frequency density of cultural venue type per LSAO (as per Dudas et al, 2017) londonLSOAProfiles[33:66] &lt;- lapply(londonLSOAProfiles[33:66], A) ## Warning in `[&lt;-.data.frame`(`*tmp*`, 33:66, value = list(Archives = ## c(23.0769230769231, : provided 35 variables to replace 34 variables Create Dummy Variables for the rating and reviews of cultural infrastructure from Airbnb #https://support.google.com/business/answer/4801187?hl=en-GB rating criteria londonLSOAProfiles$culture_rating_good &lt;- ifelse(as.numeric(londonLSOAProfiles$culture_rating) &gt;= 4, 1, 0) quantile(londonLSOAProfiles$culture_av_reviews, 0.80, na.rm=TRUE) ## 80% ## 437.0026 londonLSOAProfiles$culture_reviews_popular &lt;- ifelse(as.numeric(londonLSOAProfiles$culture_av_reviews) &gt;= 400, 1, 0) # londonLSOAProfiles &lt;- londonLSOAProfiles %&gt;% # mutate(culture_rating_loved = as.numeric(culture_rating &gt;= quantile(culture_rating, 0.90, na.rm=TRUE)), # culture_rating_liked = as.numeric(culture_rating &gt;= quantile(culture_rating, 0.75, na.rm=TRUE) &amp; culture_rating &lt; quantile(culture_rating, 0.90, na.rm=TRUE)), # culture_rating_okay = as.numeric(culture_rating &gt;= quantile(culture_rating, 0.50, na.rm=TRUE) &amp; culture_rating &lt; quantile(culture_rating, 0.75, na.rm=TRUE)), # culture_rating_disliked = as.numeric(culture_rating &gt;= quantile(culture_rating, 0.25, na.rm=TRUE) &amp; culture_rating &lt; quantile(culture_rating, 0.50, na.rm=TRUE)), # culture_rating_hated = as.numeric(culture_rating &lt;= quantile(culture_rating, 0.25, na.rm=TRUE))) # londonLSOAProfiles &lt;- londonLSOAProfiles %&gt;% # mutate(culture_rating_good = as.numeric(culture_rating &gt;= quantile(culture_rating, 0.50, na.rm=TRUE)), # culture_rating_bad = as.numeric(culture_rating &lt; quantile(culture_rating, 0.50, na.rm=TRUE))) "],
["exploratory-data-analysis.html", "Chapter 4 Exploratory Data Analysis 4.1 Airbnb EDA 4.2 Cultural infrastructure EDA", " Chapter 4 Exploratory Data Analysis Having retrieved all the necessary data, we now perform some exploratory data analysis on the variables. Before doing the EDA, we load in some very useful data visualization libraries used by this book Fundementals of Data Visualization - https://serialmentor.com/dataviz/geospatial-data.html #----load all the libraries needed # load in libraries library(tidyverse) library(scales) library(lubridate) library(ggridges) library(gridExtra) #----data visualization packages - https://serialmentor.com/dataviz/geospatial-data.html #install.packages(&quot;remotes&quot;) library(remotes) #devtools::install_github(&quot;wilkelab/cowplot&quot;) library(cowplot) #install.packages(&quot;colorspace&quot;) library(colorspace) #devtools::install_github(&quot;clauswilke/colorblindr&quot;) #https://rdrr.io/github/clauswilke/dviz.supp/ #devtools::install_github(&quot;clauswilke/dviz.supp&quot;) library(dviz.supp) #----googd bblog post on the formattable package: https://www.littlemissdata.com/blog/prettytables #install.packages(&quot;data.table&quot;) #install.packages(&quot;dplyr&quot;) #install.packages(&quot;formattable&quot;) #install.packages(&quot;tidyr&quot;) library(data.table) library(dplyr) library(formattable) library(tidyr) options(scipen = 999) Then, we set up some basic settings from this great Kaggle Kernel by X for data visualisation of exploratory data analysis of variables https://www.kaggle.com/jaseziv83/a-deep-dive-eda-into-all-variables/report #----set the plotting theme baseline theme_set(theme_minimal() + theme(axis.title.x = element_text(size = 15, hjust = 1), axis.title.y = element_text(size = 15), axis.text.x = element_text(size = 12), axis.text.y = element_text(size = 12), panel.grid.major = element_line(linetype = 2), panel.grid.minor = element_line(linetype = 2), plot.margin=unit(c(1,1,-0.5,1),&quot;cm&quot;), plot.title = element_text(size = 18, colour = &quot;grey25&quot;, face = &quot;bold&quot;), plot.subtitle = element_text(size = 16, colour = &quot;grey44&quot;))) col_pal &lt;- c(&quot;#5EB296&quot;, &quot;#4E9EBA&quot;, &quot;#F29239&quot;, &quot;#C2CE46&quot;, &quot;#FF7A7F&quot;, &quot;#4D4D4D&quot;) 4.1 Airbnb EDA First we do EDA on the Airbnb data londonLSOAProfiles_nogeom &lt;- st_set_geometry(londonLSOAProfiles, NULL) ## Error in st_set_geometry(londonLSOAProfiles, NULL): could not find function &quot;st_set_geometry&quot; a1 &lt;- londonLSOAProfiles_nogeom %&gt;% group_by(LAD11NM) %&gt;% summarise( airbnb_freq=mean(airbnb_freq), airbnb_no_reviews=mean(airbnb_no_reviews), airbnb_price=mean(airbnb_price), culture_freq=mean(culture_freq, na.rm=TRUE), culture_rating=mean(culture_rating, na.rm=TRUE), culture_av_reviews=mean(culture_av_reviews, na.rm=TRUE) ) %&gt;% arrange(desc(airbnb_freq)) %&gt;% top_n(n = 11, wt = airbnb_freq) ## Error in londonLSOAProfiles_nogeom %&gt;% group_by(LAD11NM) %&gt;% summarise(airbnb_freq = mean(airbnb_freq), : could not find function &quot;%&gt;%&quot; options(digits = 3) formattable(a1) ## Error in formattable(a1): could not find function &quot;formattable&quot; 4.1.1 Airbnb freqency distributions When looking at the distribution of Airbnb listings we see that there are some outliter. After #----this distribution function was taken from Zivkovic (2019) outlier &lt;- round(1.5 * IQR(londonLSOAProfiles$airbnb_freq), 0) plot1 &lt;- londonLSOAProfiles %&gt;% mutate(outlier = ifelse(airbnb_freq &gt; outlier, &quot;Outlier&quot;, &quot;Not Outlier&quot;)) %&gt;% ggplot(aes(x=airbnb_freq)) + geom_histogram(alpha = 0.5, fill = &quot;#5EB296&quot;, colour = &quot;#4D4D4D&quot;) + scale_x_continuous(labels = comma) + scale_y_continuous(labels = comma) + ggtitle(&quot;AIRBNB FREQUENCY&quot;, subtitle = &quot;Airbnb freqency still skewed even for non-outliers&quot;) + labs(x= &quot;Airbnb freq per LSOA&quot;, y= &quot;Count&quot;) + facet_wrap(~ outlier, scales = &quot;free&quot;) #----this distribution function was taken from Zivkovic (2019) outlier &lt;- round(1.5 * IQR(londonLSOAProfiles$airbnb_price), 0) plot2 &lt;- londonLSOAProfiles %&gt;% mutate(outlier = ifelse(airbnb_price &gt; outlier, &quot;Outlier&quot;, &quot;Not Outlier&quot;)) %&gt;% ggplot(aes(x=airbnb_price)) + geom_histogram(alpha = 0.5, fill = col_pal[2], colour = &quot;#4D4D4D&quot;) + scale_x_continuous(labels = comma) + scale_y_continuous(labels = comma) + ggtitle(&quot;AIRBNB PRICE&quot;, subtitle = &quot;Airbnb price still skewed even for non-outliers&quot;) + labs(x= &quot;Airbnb price per LSOA&quot;, y= &quot;Count&quot;) + facet_wrap(~ outlier, scales = &quot;free&quot;) #----this distribution function was taken from Zivkovic (2019) outlier &lt;- round(1.5 * IQR(londonLSOAProfiles$airbnb_av_reviews), 0) plot3 &lt;- londonLSOAProfiles %&gt;% mutate(outlier = ifelse(airbnb_av_reviews &gt; outlier, &quot;Outlier&quot;, &quot;Not Outlier&quot;)) %&gt;% ggplot(aes(x=airbnb_av_reviews)) + geom_histogram(alpha = 0.5, fill = col_pal[3], colour = &quot;#4D4D4D&quot;) + scale_x_continuous(labels = comma) + scale_y_continuous(labels = comma) + ggtitle(&quot;AIRBNB REVIEWS&quot;, subtitle = &quot;Airbnb reviews still skewed even for non-outliers&quot;) + labs(x= &quot;Airbnb reviews per LSOA&quot;, y= &quot;Count&quot;) + facet_wrap(~ outlier, scales = &quot;free&quot;) g &lt;- grid.arrange(plot1, plot2, plot3, ncol=3) #ggsave(&quot;graphs/1.png&quot;, plot = g, width = 10, height = 4) 4.1.2 Airbnb log freqency distributions Lets look at the log of Airbnb freqency #----this log distribution function was taken from Zivkovic (2019) plot4 &lt;- londonLSOAProfiles %&gt;% ggplot(aes(x= log(airbnb_freq))) + geom_histogram(alpha = 0.5, fill = &quot;#5EB296&quot;, colour = &quot;#4D4D4D&quot;) + scale_y_continuous(labels = comma) + ggtitle(&quot;LOG AIRBNB FREQ&quot;, subtitle = &quot;The variable looks a lot more workable now&quot;) + labs(x= &quot;log(Airbnb Freq)&quot;, y= &quot;Count&quot;) #----this log distribution function was taken from Zivkovic (2019) plot5 &lt;- londonLSOAProfiles %&gt;% ggplot(aes(x= log(airbnb_price))) + geom_histogram(alpha = 0.5, fill = col_pal[2], colour = &quot;#4D4D4D&quot;) + scale_y_continuous(labels = comma) + ggtitle(&quot;LOG AIRBNB PRICE&quot;, subtitle = &quot;The variable looks a lot more workable now&quot;) + labs(x= &quot;log(Airbnb price)&quot;, y= &quot;Count&quot;) #----this log distribution function was taken from Zivkovic (2019) plot6 &lt;- londonLSOAProfiles %&gt;% ggplot(aes(x= log(airbnb_no_reviews))) + geom_histogram(alpha = 0.5, fill = col_pal[3], colour = &quot;#4D4D4D&quot;) + scale_y_continuous(labels = comma) + ggtitle(&quot;LOG AIRBNB REVIEWS&quot;, subtitle = &quot;The variable looks a lot more workable now&quot;) + labs(x= &quot;log(Airbnb reviews)&quot;, y= &quot;Count&quot;) grid.arrange(plot4, plot5, plot6, ncol=3) 4.1.3 Airbnb Inner vs Outer London Lets look at Airbnb frequency in Inner vs Outer London #----this log distribution function was taken from Zivkovic (2019) plot7 &lt;- londonLSOAProfiles %&gt;% ggplot(aes(x= log(airbnb_freq), fill = as.character(InnerOuter))) + geom_density(alpha = 0.5, adjust = 2) + scale_fill_manual(values = col_pal) + ggtitle(&quot;THERE ARE MORE LISTINGS IN INNER LONDON&quot;, subtitle = &quot;&quot;) + labs(x= &quot;log(Airbnb Freq)&quot;) + theme(axis.title.y = element_blank(), legend.position = &quot;top&quot;) #----this log distribution function was taken from Zivkovic (2019) plot8 &lt;- londonLSOAProfiles %&gt;% ggplot(aes(x= log(airbnb_price), fill = as.character(InnerOuter))) + geom_density(alpha = 0.5, adjust = 2) + scale_fill_manual(values = col_pal) + ggtitle(&quot;LISTINGS ARE MORE EXPENSIVE IN INNER LONDON&quot;, subtitle = &quot;&quot;) + labs(x= &quot;log(Airbnb Price)&quot;) + theme(axis.title.y = element_blank(), legend.position = &quot;top&quot;) #----this log distribution function was taken from Zivkovic (2019) plot9 &lt;- londonLSOAProfiles %&gt;% ggplot(aes(x= log(airbnb_no_reviews), fill = as.character(InnerOuter))) + geom_density(alpha = 0.5, adjust = 2) + scale_fill_manual(values = col_pal) + ggtitle(&quot;LISTINGS ARE MORE EXPENSIVE IN INNER LONDON&quot;, subtitle = &quot;&quot;) + labs(x= &quot;log(Airbnb Price)&quot;) + theme(axis.title.y = element_blank(), legend.position = &quot;top&quot;) grid.arrange(plot7, plot8, plot9, ncol=3) 4.2 Cultural infrastructure EDA Explaination. 4.2.1 Cultural infrastructure venues #----this distribution function was taken from Zivkovic (2019) outlier &lt;- round(1.5 * IQR(londonLSOAProfiles$culture_freq, na.rm = TRUE), 0) plot10 &lt;- londonLSOAProfiles %&gt;% mutate(outlier = ifelse(culture_freq &gt; outlier, &quot;Outlier&quot;, &quot;Not Outlier&quot;)) %&gt;% ggplot(aes(x=culture_freq)) + geom_histogram(alpha = 0.5, fill = &quot;#5EB296&quot;, colour = &quot;#4D4D4D&quot;) + scale_x_continuous(labels = comma) + scale_y_continuous(labels = comma) + ggtitle(&quot;CULTURAL INFRASTRUCUTRE IN FREQUENCY&quot;, subtitle = &quot;Cultural Infrastructure freqency still skewed even for non-outliers&quot;) + labs(x= &quot;Cultural Infrastructure freq per LSOA&quot;, y= &quot;Count&quot;) + facet_wrap(~ outlier, scales = &quot;free&quot;) #----this distribution function was taken from Zivkovic (2019) outlier &lt;- round(1.5 * IQR(londonLSOAProfiles$culture_rating, na.rm = TRUE), 0) plot11 &lt;- londonLSOAProfiles %&gt;% mutate(outlier = ifelse(culture_rating &gt; outlier, &quot;Outlier&quot;, &quot;Not Outlier&quot;)) %&gt;% ggplot(aes(x=culture_rating)) + geom_histogram(alpha = 0.5, fill = col_pal[2], colour = &quot;#4D4D4D&quot;) + scale_x_continuous(labels = comma) + scale_y_continuous(labels = comma) + ggtitle(&quot;CULTURAL INFRASTRUCUTRE Rating&quot;, subtitle = &quot;Cultural Infrastructure price still skewed even for non-outliers&quot;) + labs(x= &quot;Cultural Infrastructure price per LSOA&quot;, y= &quot;Count&quot;) + facet_wrap(~ outlier, scales = &quot;free&quot;) #----this distribution function was taken from Zivkovic (2019) outlier &lt;- round(1.5 * IQR(londonLSOAProfiles$culture_no_reviews, na.rm = TRUE), 0) plot12 &lt;- londonLSOAProfiles %&gt;% mutate(outlier = ifelse(culture_no_reviews &gt; outlier, &quot;Outlier&quot;, &quot;Not Outlier&quot;)) %&gt;% ggplot(aes(x=culture_no_reviews)) + geom_histogram(alpha = 0.5, fill = col_pal[3], colour = &quot;#4D4D4D&quot;) + scale_x_continuous(labels = comma) + scale_y_continuous(labels = comma) + ggtitle(&quot;CULTURAL INFRASTRUCUTRE REVIEWS&quot;, subtitle = &quot;Cultural Infrastructure reviews still skewed even for non-outliers&quot;) + labs(x= &quot;Cultural Infrastructure reviews per LSOA&quot;, y= &quot;Count&quot;) + facet_wrap(~ outlier, scales = &quot;free&quot;) grid.arrange(plot10, plot11, plot12, ncol=3) ## Warning: Removed 2116 rows containing non-finite values (stat_bin). ## Warning: Removed 2116 rows containing non-finite values (stat_bin). ## Warning: Removed 2116 rows containing non-finite values (stat_bin). 4.2.2 Cultural infrastructure ratings #----this log distribution function was taken from Zivkovic (2019) plot13 &lt;- londonLSOAProfiles %&gt;% ggplot(aes(x= log(culture_freq))) + geom_histogram(alpha = 0.5, fill = &quot;#5EB296&quot;, colour = &quot;#4D4D4D&quot;) + scale_y_continuous(labels = comma) + ggtitle(&quot;LOG CULTURE FREQ&quot;, subtitle = &quot;The variable looks a lot more workable now&quot;) + labs(x= &quot;log(Airbnb Freq)&quot;, y= &quot;Count&quot;) #----this log distribution function was taken from Zivkovic (2019) plot14 &lt;- londonLSOAProfiles %&gt;% ggplot(aes(x= culture_rating)) + geom_histogram(alpha = 0.5, fill = col_pal[2], colour = &quot;#4D4D4D&quot;) + scale_y_continuous(labels = comma) + ggtitle(&quot;LOG CULTURE RATINGS&quot;, subtitle = &quot;The variable looks a lot more workable now&quot;) + labs(x= &quot;log(Airbnb price)&quot;, y= &quot;Count&quot;) #----this log distribution function was taken from Zivkovic (2019) plot15 &lt;- londonLSOAProfiles %&gt;% ggplot(aes(x= log(culture_no_reviews))) + geom_histogram(alpha = 0.5, fill = col_pal[3], colour = &quot;#4D4D4D&quot;) + scale_y_continuous(labels = comma) + ggtitle(&quot;LOG CULTURE REVIEWS&quot;, subtitle = &quot;The variable looks a lot more workable now&quot;) + labs(x= &quot;log(Airbnb reviews)&quot;, y= &quot;Count&quot;) grid.arrange(plot13, plot14, plot15, ncol=3) ## Warning: Removed 2116 rows containing non-finite values (stat_bin). ## Warning: Removed 2116 rows containing non-finite values (stat_bin). ## Warning: Removed 2116 rows containing non-finite values (stat_bin). #gather_count &lt;- londonLSOAProfiles %&gt;% gather(culture, culture_density, Archives:Theatres) #gather_ratings &lt;- londonLSOAProfiles %&gt;% gather(culture, culture_rating, Archives:Theatres) 4.2.3 all variables #list1 &lt;- cbind(list1, seq.int(nrow(list1))) ##you will notice that there are some non-numeric columns, we want to exclue these, and drop the geometry #LondonSub &lt;- LondonWardsSF[,c(1:73,83:86)] #----find the column numbers for first and last cultural venue type which( colnames(londonLSOAProfiles)==&quot;bame_p&quot; ) ## [1] 17 which( colnames(londonLSOAProfiles)==&quot;housing&quot; ) ## [1] 28 #check which variables are numeric first list1 &lt;- as.data.frame(cbind(lapply(londonLSOAProfiles, class))) list1 &lt;- cbind(list1, seq.int(nrow(list1))) list1 ## V1 seq.int(nrow(list1)) ## LSOA11CD character 1 ## LSOA11NM factor 2 ## MSOA11CD factor 3 ## MSOA11NM factor 4 ## LAD11CD factor 5 ## LAD11NM factor 6 ## RGN11CD factor 7 ## RGN11NM factor 8 ## USUALRES integer 9 ## HHOLDRES integer 10 ## COMESTRES integer 11 ## POPDEN numeric 12 ## HHOLDS integer 13 ## AVHHOLDSZ numeric 14 ## areaLSOA numeric 15 ## pop_density numeric 16 ## bame_p numeric 17 ## nonUK numeric 18 ## house_own numeric 19 ## house_mortg numeric 20 ## house_price numeric 21 ## employees numeric 22 ## education numeric 23 ## income numeric 24 ## transport numeric 25 ## age16_29 numeric 26 ## age30_44 numeric 27 ## housing numeric 28 ## airbnb_freq numeric 29 ## airbnb_price numeric 30 ## airbnb_no_reviews numeric 31 ## airbnb_av_reviews numeric 32 ## Archives numeric 33 ## Artists workspaces numeric 34 ## Arts centres numeric 35 ## Cinemas numeric 36 ## Commercial galleries numeric 37 ## Community centres numeric 38 ## Creative co-working desk space numeric 39 ## Creative workspaces numeric 40 ## Dance performance venues numeric 41 ## Dance rehearsal studios numeric 42 ## Fashion and design numeric 43 ## Jewellery design numeric 44 ## Large media production studios numeric 45 ## Legal street art walls numeric 46 ## LGBT+ night time venues numeric 47 ## Libraries numeric 48 ## Live in artists&#39; workspace numeric 49 ## Makerspaces numeric 50 ## Making and manufacturing numeric 51 ## Museums and public galleries numeric 52 ## Music (office based businesses) numeric 53 ## Music recording studios numeric 54 ## Music rehearsal studios numeric 55 ## Music venues (all) numeric 56 ## Music venues (grassroots) numeric 57 ## Outdoor spaces for cultural use numeric 58 ## Prop and costume making numeric 59 ## Pubs numeric 60 ## Set and exhibition building numeric 61 ## Skate Parks numeric 62 ## Textile design numeric 63 ## Theatre rehearsal studio numeric 64 ## Theatres numeric 65 ## culture_freq numeric 66 ## culture_rating numeric 67 ## culture_no_reviews numeric 68 ## culture_av_reviews numeric 69 ## InnerOuter factor 70 ## geometry sfc_MULTIPOLYGON, sfc 71 ## young_p numeric 72 ## culture_rating_good numeric 73 ## culture_reviews_popular numeric 74 #you will notice that there are some non-numeric columns, we want to exclue these, and drop the geometry londonSub &lt;- londonLSOAProfiles[,c(1:2, 17:28)] #make sure the geometry is null or we will get errors - also create some subsets so that we can see our data better #londonSub &lt;- subset(londonLSOAProfiles, select = c(17:28)) londonSub &lt;- st_set_geometry(londonSub, NULL) library(reshape2) londonSub &lt;- melt(londonSub, id.vars = 1:2) attach(londonSub) hist2 &lt;- ggplot(londonSub, aes(x=value)) + geom_histogram(aes(y = ..density..)) + geom_density(colour=&quot;red&quot;, size=1, adjust=1) hist2 + facet_wrap(~ variable, scales=&quot;free&quot;) ## Warning: Removed 2 rows containing non-finite values (stat_bin). ## Warning: Removed 2 rows containing non-finite values (stat_density). Correlations # ggplot(londonLSOAProfiles, aes(log(airbnb_freq), log(airbnb_price))) + # geom_point(pch = 21, fill = &quot;gray25&quot;, color = &quot;white&quot;, size = 2.5) + # scale_x_continuous(name = &quot;airbnb freq per LSOA (km2)&quot;) + # scale_y_continuous(name = &quot;airbnb price per LSOA (km2)&quot;) + # theme_dviz_grid() ggplot(londonLSOAProfiles, aes(log(airbnb_freq), log(airbnb_price), fill = InnerOuter)) + geom_point(pch = 21, color = &quot;white&quot;, size = 2.5) + scale_x_continuous(name = &quot;airbnb freq per LSOA (km2)&quot;) + scale_y_continuous(name = &quot;airbnb price per LSOA (km2)&quot;) + scale_fill_manual( values = c(&#39;Inner London&#39; = &quot;#D55E00&quot;, &#39;Outer London&#39; = &quot;#0072B2&quot;), breaks = c(&quot;F&quot;, &quot;M&quot;), labels = c(&quot;female birds &quot;, &quot;male birds&quot;), name = NULL, guide = guide_legend( direction = &quot;horizontal&quot;, override.aes = list(size = 3) ) ) + theme_dviz_grid() + theme( #legend.position = c(1, 0.01), #legend.justification = c(1, 0), legend.position = &quot;top&quot;, legend.justification = &quot;right&quot;, legend.box.spacing = unit(3.5, &quot;pt&quot;), # distance between legend and plot legend.text = element_text(vjust = 0.6), legend.spacing.x = unit(2, &quot;pt&quot;), legend.background = element_rect(fill = &quot;white&quot;, color = NA), legend.key.width = unit(10, &quot;pt&quot;) ) ggplot(londonLSOAProfiles, aes(log(culture_no_reviews), log(airbnb_no_reviews), fill = InnerOuter)) + geom_point(pch = 21, color = &quot;white&quot;, size = 2.5) + scale_x_continuous(name = &quot;culture_no_reviews PER LSOA (km2)&quot;) + scale_y_continuous(name = &quot;airbnb_no_reviews LSOA (km2)&quot;) + scale_fill_manual( values = c(&#39;Inner London&#39; = &quot;#D55E00&quot;, &#39;Outer London&#39; = &quot;#0072B2&quot;), breaks = c(&quot;F&quot;, &quot;M&quot;), labels = c(&quot;female birds &quot;, &quot;male birds&quot;), name = NULL, guide = guide_legend( direction = &quot;horizontal&quot;, override.aes = list(size = 3) ) ) + theme_dviz_grid() + theme( #legend.position = c(1, 0.01), #legend.justification = c(1, 0), legend.position = &quot;top&quot;, legend.justification = &quot;right&quot;, legend.box.spacing = unit(3.5, &quot;pt&quot;), # distance between legend and plot legend.text = element_text(vjust = 0.6), legend.spacing.x = unit(2, &quot;pt&quot;), legend.background = element_rect(fill = &quot;white&quot;, color = NA), legend.key.width = unit(10, &quot;pt&quot;) ) ## Warning: Removed 2116 rows containing missing values (geom_point). ggplot(londonLSOAProfiles, aes(log(culture_no_reviews), log(airbnb_freq), fill = InnerOuter)) + geom_point(pch = 21, color = &quot;white&quot;, size = 2.5) + scale_x_continuous(name = &quot;culture_no_reviews PER LSOA (km2)&quot;) + scale_y_continuous(name = &quot;airbnb_freq LSOA (km2)&quot;) + scale_fill_manual( values = c(&#39;Inner London&#39; = &quot;#D55E00&quot;, &#39;Outer London&#39; = &quot;#0072B2&quot;), breaks = c(&quot;F&quot;, &quot;M&quot;), labels = c(&quot;female birds &quot;, &quot;male birds&quot;), name = NULL, guide = guide_legend( direction = &quot;horizontal&quot;, override.aes = list(size = 3) ) ) + theme_dviz_grid() + theme( #legend.position = c(1, 0.01), #legend.justification = c(1, 0), legend.position = &quot;top&quot;, legend.justification = &quot;right&quot;, legend.box.spacing = unit(3.5, &quot;pt&quot;), # distance between legend and plot legend.text = element_text(vjust = 0.6), legend.spacing.x = unit(2, &quot;pt&quot;), legend.background = element_rect(fill = &quot;white&quot;, color = NA), legend.key.width = unit(10, &quot;pt&quot;) ) ## Warning: Removed 2116 rows containing missing values (geom_point). ggplot(londonLSOAProfiles, aes(log(culture_no_reviews), log(airbnb_price), fill = InnerOuter)) + geom_point(pch = 21, color = &quot;white&quot;, size = 2.5) + scale_x_continuous(name = &quot;culture_no_reviews PER LSOA (km2)&quot;) + scale_y_continuous(name = &quot;airbnb_price LSOA (km2)&quot;) + scale_fill_manual( values = c(&#39;Inner London&#39; = &quot;#D55E00&quot;, &#39;Outer London&#39; = &quot;#0072B2&quot;), breaks = c(&quot;F&quot;, &quot;M&quot;), labels = c(&quot;female birds &quot;, &quot;male birds&quot;), name = NULL, guide = guide_legend( direction = &quot;horizontal&quot;, override.aes = list(size = 3) ) ) + theme_dviz_grid() + theme( #legend.position = c(1, 0.01), #legend.justification = c(1, 0), legend.position = &quot;top&quot;, legend.justification = &quot;right&quot;, legend.box.spacing = unit(3.5, &quot;pt&quot;), # distance between legend and plot legend.text = element_text(vjust = 0.6), legend.spacing.x = unit(2, &quot;pt&quot;), legend.background = element_rect(fill = &quot;white&quot;, color = NA), legend.key.width = unit(10, &quot;pt&quot;) ) ## Warning: Removed 2116 rows containing missing values (geom_point). ggplot(londonLSOAProfiles, aes(log(culture_no_reviews), log(house_price), fill = InnerOuter)) + geom_point(pch = 21, color = &quot;white&quot;, size = 2.5) + scale_x_continuous(name = &quot;culture_no_reviews PER LSOA (km2)&quot;) + scale_y_continuous(name = &quot;house_price LSOA (km2)&quot;) + scale_fill_manual( values = c(&#39;Inner London&#39; = &quot;#D55E00&quot;, &#39;Outer London&#39; = &quot;#0072B2&quot;), breaks = c(&quot;F&quot;, &quot;M&quot;), labels = c(&quot;female birds &quot;, &quot;male birds&quot;), name = NULL, guide = guide_legend( direction = &quot;horizontal&quot;, override.aes = list(size = 3) ) ) + theme_dviz_grid() + theme( #legend.position = c(1, 0.01), #legend.justification = c(1, 0), legend.position = &quot;top&quot;, legend.justification = &quot;right&quot;, legend.box.spacing = unit(3.5, &quot;pt&quot;), # distance between legend and plot legend.text = element_text(vjust = 0.6), legend.spacing.x = unit(2, &quot;pt&quot;), legend.background = element_rect(fill = &quot;white&quot;, color = NA), legend.key.width = unit(10, &quot;pt&quot;) ) ## Warning: Removed 2118 rows containing missing values (geom_point). ggplot(londonLSOAProfiles, aes(log(culture_freq), log(house_price), fill = InnerOuter)) + geom_point(pch = 21, color = &quot;white&quot;, size = 2.5) + scale_x_continuous(name = &quot;culture_freq PER LSOA (km2)&quot;) + scale_y_continuous(name = &quot;house_price LSOA (km2)&quot;) + scale_fill_manual( values = c(&#39;Inner London&#39; = &quot;#D55E00&quot;, &#39;Outer London&#39; = &quot;#0072B2&quot;), breaks = c(&quot;F&quot;, &quot;M&quot;), labels = c(&quot;female birds &quot;, &quot;male birds&quot;), name = NULL, guide = guide_legend( direction = &quot;horizontal&quot;, override.aes = list(size = 3) ) ) + theme_dviz_grid() + theme( #legend.position = c(1, 0.01), #legend.justification = c(1, 0), legend.position = &quot;top&quot;, legend.justification = &quot;right&quot;, legend.box.spacing = unit(3.5, &quot;pt&quot;), # distance between legend and plot legend.text = element_text(vjust = 0.6), legend.spacing.x = unit(2, &quot;pt&quot;), legend.background = element_rect(fill = &quot;white&quot;, color = NA), legend.key.width = unit(10, &quot;pt&quot;) ) ## Warning: Removed 2118 rows containing missing values (geom_point). ggplot(londonLSOAProfiles, aes(culture_rating, log(house_price), fill = InnerOuter)) + geom_point(pch = 21, color = &quot;white&quot;, size = 2.5) + scale_x_continuous(name = &quot;culture_rating PER LSOA (km2)&quot;) + scale_y_continuous(name = &quot;house_price LSOA (km2)&quot;) + scale_fill_manual( values = c(&#39;Inner London&#39; = &quot;#D55E00&quot;, &#39;Outer London&#39; = &quot;#0072B2&quot;), breaks = c(&quot;F&quot;, &quot;M&quot;), labels = c(&quot;female birds &quot;, &quot;male birds&quot;), name = NULL, guide = guide_legend( direction = &quot;horizontal&quot;, override.aes = list(size = 3) ) ) + theme_dviz_grid() + theme( #legend.position = c(1, 0.01), #legend.justification = c(1, 0), legend.position = &quot;top&quot;, legend.justification = &quot;right&quot;, legend.box.spacing = unit(3.5, &quot;pt&quot;), # distance between legend and plot legend.text = element_text(vjust = 0.6), legend.spacing.x = unit(2, &quot;pt&quot;), legend.background = element_rect(fill = &quot;white&quot;, color = NA), legend.key.width = unit(10, &quot;pt&quot;) ) ## Warning: Removed 2118 rows containing missing values (geom_point). "],
["maps.html", "Chapter 5 Maps", " Chapter 5 Maps library(tmap) londonLSOAProfiles_inner &lt;- londonLSOAProfiles[londonLSOAProfiles$InnerOuter == &#39;Inner London&#39;,] #http://www.stat.columbia.edu/~tzheng/files/Rcolor.pdf culture_dots_london &lt;- tm_shape(londonLSOAProfiles) + tm_fill(col = &#39;white&#39;) + tm_borders(col = &#39;dimgray&#39;, lwd = 0.3, lty = &quot;solid&quot;) + tm_polygons() + tm_shape(culture[londonLSOAProfiles, ]) + tm_dots(col = &quot;Cultural.Venue.Type&quot;) + tm_layout(frame=FALSE) + tm_legend(show =FALSE) + tm_credits(&quot;Greater London&quot;, position = c(0, 0.9), size=0.7) culture_dots_inner_london &lt;- tm_shape(londonLSOAProfiles_inner) + tm_borders(col = &#39;dimgray&#39;, lwd = 0.3, lty = &quot;solid&quot;) + tm_polygons() + tm_shape(culture[londonLSOAProfiles_inner,]) + tm_dots(col = &quot;Cultural.Venue.Type&quot;) + tm_layout(frame=FALSE) + tm_legend(show =FALSE) + tm_credits(&quot;Inner London&quot;, position = c(0.1, 0.9), size=0.7) legend1 &lt;- tm_shape(londonLSOAProfiles) + tm_polygons() + tm_shape(culture[londonLSOAProfiles,]) + tm_dots(col = &quot;Cultural.Venue.Type&quot;) + tm_scale_bar(position=c(0.2, 0.6), text.size=0.6) + tm_compass(north=0, position=c(0.2, 0.8)) + tm_layout(legend.only = TRUE, legend.position=c(0.6, 0.6), asp=0, legend.stack = &quot;horizontal&quot;, legend.width = 1 #legend.outside = TRUE, legend.outside.position = &quot;bottom&quot; ) + tm_credits(&quot;Source: data.london - Cultural Infrasturcture Map&quot;, position=c(0.1, 0.3)) culture_dot_map = tmap_arrange(culture_dots_london, culture_dots_inner_london, legend1, ncol=2) culture_dot_map ## Warning: The shape londonLSOAProfiles is invalid. See sf::st_is_valid ## Warning: One tm layer group has duplicated layer types, which are omitted. To ## draw multiple layers of the same type, use multiple layer groups (i.e. specify ## tm_shape prior to each of them). ## Warning: Number of levels of the variable &quot;Cultural.Venue.Type&quot; is 33, which ## is larger than max.categories (which is 30), so levels are combined. Set ## tmap_options(max.categories = 33) in the layer function to show all levels. ## Warning: The shape londonLSOAProfiles_inner is invalid. See sf::st_is_valid ## Warning: One tm layer group has duplicated layer types, which are omitted. To ## draw multiple layers of the same type, use multiple layer groups (i.e. specify ## tm_shape prior to each of them). ## Warning: Number of levels of the variable &quot;Cultural.Venue.Type&quot; is 33, which ## is larger than max.categories (which is 30), so levels are combined. Set ## tmap_options(max.categories = 33) in the layer function to show all levels. ## Warning: The shape londonLSOAProfiles is invalid. See sf::st_is_valid ## Warning: Number of levels of the variable &quot;Cultural.Venue.Type&quot; is 33, which ## is larger than max.categories (which is 30), so levels are combined. Set ## tmap_options(max.categories = 33) in the layer function to show all levels. tmap_save(culture_dot_map, filename = &quot;maps/cultural_infrastructure_dots_lsoa.png&quot;) ## Warning: The shape londonLSOAProfiles is invalid. See sf::st_is_valid ## Warning: One tm layer group has duplicated layer types, which are omitted. To ## draw multiple layers of the same type, use multiple layer groups (i.e. specify ## tm_shape prior to each of them). ## Warning: Number of levels of the variable &quot;Cultural.Venue.Type&quot; is 33, which ## is larger than max.categories (which is 30), so levels are combined. Set ## tmap_options(max.categories = 33) in the layer function to show all levels. ## Warning: The shape londonLSOAProfiles_inner is invalid. See sf::st_is_valid ## Warning: One tm layer group has duplicated layer types, which are omitted. To ## draw multiple layers of the same type, use multiple layer groups (i.e. specify ## tm_shape prior to each of them). ## Warning: Number of levels of the variable &quot;Cultural.Venue.Type&quot; is 33, which ## is larger than max.categories (which is 30), so levels are combined. Set ## tmap_options(max.categories = 33) in the layer function to show all levels. ## Warning: The shape londonLSOAProfiles is invalid. See sf::st_is_valid ## Warning: Number of levels of the variable &quot;Cultural.Venue.Type&quot; is 33, which ## is larger than max.categories (which is 30), so levels are combined. Set ## tmap_options(max.categories = 33) in the layer function to show all levels. Culture frequency density map culture_freq_london &lt;- tm_shape(londonLSOAProfiles) + tm_borders(col = &#39;dimgray&#39;, lwd = 0.3, lty = &quot;solid&quot;) + tm_polygons(col = &#39;culture_freq&#39;, style = &#39;log10&#39;) + tm_layout(frame=FALSE) + tm_legend(show =FALSE) + tm_credits(&quot;Greater London&quot;, position = c(0.1, 0.9), size=0.7 ) culture_freq_inner_london &lt;- tm_shape(londonLSOAProfiles_inner) + tm_borders(col = &#39;dimgray&#39;, lwd = 0.3, lty = &quot;solid&quot;) + tm_polygons(col = &#39;culture_freq&#39;,style = &#39;log10&#39;) + tm_layout(frame=FALSE) + tm_legend(show =FALSE) + tm_credits(&quot;Inner London&quot;, position = c(0, 0.9), size=0.7) legend1 &lt;- tm_shape(londonLSOAProfiles) + tm_polygons(title = &quot;Culture Freq (km2)&quot;, col = &quot;culture_freq&quot;) + tm_scale_bar(position=c(0.2, 0.6), text.size=0.6) + tm_compass(north=0, position=c(0.2, 0.8)) + tm_layout(legend.only = TRUE, legend.position=c(0.6, 0.6), asp=0.1) + tm_credits(&quot;Source: data.london - Cultural Infrasturcture Map&quot;, position=c(0.1, 0.3)) legend2 &lt;- tm_shape(londonLSOAProfiles_inner) + tm_polygons(title = &quot;Culture Freq (km2)&quot;, col =&quot;culture_freq&quot;) + tm_scale_bar(position=c(0.2, 0.6), text.size=0.6) + tm_compass(north=0, position=c(0.2, 0.8)) + tm_layout(title = &quot;Cultural Freq&quot;, legend.only = TRUE, legend.position=c(0.6, 0.6), asp=0.1) #+ tm_credits(&quot;Source: data.london - Cultural Infrasturcture Map&quot;, position=c(0, 0.3)) culture_freq_map = tmap_arrange(culture_freq_london, culture_freq_inner_london, legend1, legend2, ncol=2) tmap_save(culture_freq_map, filename = &quot;maps/cultural_infrastructure_density_lsoa.png&quot;) ## Warning: The shape londonLSOAProfiles is invalid. See sf::st_is_valid ## Warning: One tm layer group has duplicated layer types, which are omitted. To ## draw multiple layers of the same type, use multiple layer groups (i.e. specify ## tm_shape prior to each of them). ## Warning: The shape londonLSOAProfiles_inner is invalid. See sf::st_is_valid ## Warning: One tm layer group has duplicated layer types, which are omitted. To ## draw multiple layers of the same type, use multiple layer groups (i.e. specify ## tm_shape prior to each of them). ## Warning: The shape londonLSOAProfiles is invalid. See sf::st_is_valid ## Warning: The shape londonLSOAProfiles_inner is invalid. See sf::st_is_valid #culture_freq_map Culture rating map culture_rating_london &lt;- tm_shape(londonLSOAProfiles) + tm_borders(col = &#39;dimgray&#39;, lwd = 0.3, lty = &quot;solid&quot;) + tm_polygons(col = &#39;culture_rating&#39;, style = &#39;quantile&#39;) + tm_layout(frame=FALSE) + tm_legend(show =FALSE) + tm_credits(&quot;Greater London&quot;, position = c(0.1, 0.9), size=0.7 ) culture_rating_inner_london &lt;- tm_shape(londonLSOAProfiles_inner) + tm_borders(col = &#39;dimgray&#39;, lwd = 0.3, lty = &quot;solid&quot;) + tm_polygons(col = &#39;culture_rating&#39;, style = &#39;quantile&#39;) + tm_layout(frame=FALSE) + tm_legend(show =FALSE) + tm_credits(&quot;Inner London&quot;, position = c(0, 0.9), size=0.7) legend1 &lt;- tm_shape(londonLSOAProfiles) + tm_polygons(title = &quot;Culture Rating&quot;, col = &quot;culture_rating&quot;) + tm_scale_bar(position=c(0.2, 0.6), text.size=0.6) + tm_compass(north=0, position=c(0.2, 0.8)) + tm_layout(legend.only = TRUE, legend.position=c(0.6, 0.4), asp=0.1) + tm_credits(&quot;Source: data.london - Cultural Infrasturcture Map&quot;, position=c(0.1, 0.3)) legend2 &lt;- tm_shape(londonLSOAProfiles_inner) + tm_polygons(title = &quot;Culture Rating&quot;, col =&quot;culture_rating&quot;) + tm_scale_bar(position=c(0.2, 0.6), text.size=0.6) + tm_compass(north=0, position=c(0.2, 0.8)) + tm_layout(legend.only = TRUE, legend.position=c(0.6, 0.4), asp=0.1) #+ tm_credits(&quot;Source: data.london - Cultural Infrasturcture Map&quot;, position=c(0, 0.3)) culture_rating_map = tmap_arrange(culture_rating_london, culture_rating_inner_london, legend1, legend2, ncol=2) tmap_save(culture_rating_map, filename = &quot;maps/cultural_infrastructure_rating_lsoa.png&quot;) ## Warning: The shape londonLSOAProfiles is invalid. See sf::st_is_valid ## Warning: One tm layer group has duplicated layer types, which are omitted. To ## draw multiple layers of the same type, use multiple layer groups (i.e. specify ## tm_shape prior to each of them). ## Warning: The shape londonLSOAProfiles_inner is invalid. See sf::st_is_valid ## Warning: One tm layer group has duplicated layer types, which are omitted. To ## draw multiple layers of the same type, use multiple layer groups (i.e. specify ## tm_shape prior to each of them). ## Warning: The shape londonLSOAProfiles is invalid. See sf::st_is_valid ## Warning: The shape londonLSOAProfiles_inner is invalid. See sf::st_is_valid #culture_rating_map Airbnb freq density map - Supply #----------------------------------- airbnb_freq_london &lt;- tm_shape(londonLSOAProfiles) + tm_borders(col = &#39;dimgray&#39;, lwd = 0.3, lty = &quot;solid&quot;) + tm_polygons(col = &#39;airbnb_freq&#39;, style = &#39;order&#39;) + tm_layout(title = &#39;Supply&#39;, frame=FALSE) + tm_legend(show =FALSE) + tm_credits(&quot;Greater London&quot;, position = c(0.1, 0.9), size=0.7 ) airbnb_freq_inner_london &lt;- tm_shape(londonLSOAProfiles_inner) + tm_borders(col = &#39;dimgray&#39;, lwd = 0.3, lty = &quot;solid&quot;) + tm_polygons(col = &#39;airbnb_freq&#39;, style = &#39;order&#39;) + tm_layout(frame=FALSE) + tm_legend(show =FALSE) + tm_credits(&quot;Inner London&quot;, position = c(0, 0.9), size=0.7) legend1 &lt;- tm_shape(londonLSOAProfiles) + tm_polygons(title = &quot;Airbnb Freq (km2)&quot;, col = &quot;airbnb_freq&quot;) + tm_scale_bar(position=c(0.2, 0.6), text.size=0.6) + tm_compass(north=0, position=c(0.2, 0.8)) + tm_layout(legend.only = TRUE, legend.position=c(0.6, 0.4), asp=0.1) + tm_credits(&quot;Source: Inside Airbnb&quot;, position=c(0.1, 0.3)) legend2 &lt;- tm_shape(londonLSOAProfiles_inner) + tm_polygons(title = &quot;Airbnb Freq (km2)&quot;, col =&quot;airbnb_freq&quot;) + tm_scale_bar(position=c(0.2, 0.6), text.size=0.6) + tm_compass(north=0, position=c(0.2, 0.8)) + tm_layout(legend.only = TRUE, legend.position=c(0.6, 0.4), asp=0.1) #+ tm_credits(&quot;Source: data.london - Cultural Infrasturcture Map&quot;, position=c(0, 0.3)) airbnb_freq_map = tmap_arrange(airbnb_freq_london, airbnb_freq_inner_london, legend1, legend2, ncol=2) tmap_save(airbnb_freq_map, filename = &quot;maps/airbnb_freq_lsoa.png&quot;) ## Warning: The shape londonLSOAProfiles is invalid. See sf::st_is_valid ## Warning: One tm layer group has duplicated layer types, which are omitted. To ## draw multiple layers of the same type, use multiple layer groups (i.e. specify ## tm_shape prior to each of them). ## Warning: The shape londonLSOAProfiles_inner is invalid. See sf::st_is_valid ## Warning: One tm layer group has duplicated layer types, which are omitted. To ## draw multiple layers of the same type, use multiple layer groups (i.e. specify ## tm_shape prior to each of them). ## Warning: The shape londonLSOAProfiles is invalid. See sf::st_is_valid ## Warning: The shape londonLSOAProfiles_inner is invalid. See sf::st_is_valid #----------------------------------- airbnb_reviews_london &lt;- tm_shape(londonLSOAProfiles) + tm_borders(col = &#39;dimgray&#39;, lwd = 0.3, lty = &quot;solid&quot;) + tm_polygons(col = &#39;airbnb_no_reviews&#39;, style = &#39;order&#39;) + tm_layout(title = &#39;Demand&#39;, frame=FALSE) + tm_legend(show =FALSE) + tm_credits(&quot;Greater London&quot;, position = c(0.1, 0.9), size=0.7 ) airbnb_reviews_inner_london &lt;- tm_shape(londonLSOAProfiles_inner) + tm_borders(col = &#39;dimgray&#39;, lwd = 0.3, lty = &quot;solid&quot;) + tm_polygons(col = &#39;airbnb_no_reviews&#39;, style = &#39;order&#39;) + tm_layout(frame=FALSE) + tm_legend(show =FALSE) + tm_credits(&quot;Inner London&quot;, position = c(0, 0.9), size=0.7) legend3 &lt;- tm_shape(londonLSOAProfiles) + tm_polygons(title = &quot;Airbnb Reviews (km2)&quot;, col = &quot;airbnb_no_reviews&quot;) + tm_scale_bar(position=c(0.2, 0.6), text.size=0.6) + tm_compass(north=0, position=c(0.2, 0.8)) + tm_layout(legend.only = TRUE, legend.position=c(0.6, 0.4), asp=0.1) + tm_credits(&quot;Source: Inside Airbnb&quot;, position=c(0.1, 0.3)) legend4 &lt;- tm_shape(londonLSOAProfiles_inner) + tm_polygons(title = &quot;Airbnb Reviews (km2)&quot;, col =&quot;airbnb_no_reviews&quot;) + tm_scale_bar(position=c(0.2, 0.6), text.size=0.6) + tm_compass(north=0, position=c(0.2, 0.8)) + tm_layout(legend.only = TRUE, legend.position=c(0.6, 0.4), asp=0.1) #+ tm_credits(&quot;Source: data.london - Cultural Infrasturcture Map&quot;, position=c(0, 0.3)) airbnb_reviews_map = tmap_arrange(airbnb_reviews_london, airbnb_reviews_inner_london, legend3, legend4, ncol=2) tmap_save(airbnb_reviews_map, filename = &quot;maps/airbnb_reviews_lsoa.png&quot;) ## Warning: The shape londonLSOAProfiles is invalid. See sf::st_is_valid ## Warning: One tm layer group has duplicated layer types, which are omitted. To ## draw multiple layers of the same type, use multiple layer groups (i.e. specify ## tm_shape prior to each of them). ## Warning: The shape londonLSOAProfiles_inner is invalid. See sf::st_is_valid ## Warning: One tm layer group has duplicated layer types, which are omitted. To ## draw multiple layers of the same type, use multiple layer groups (i.e. specify ## tm_shape prior to each of them). ## Warning: The shape londonLSOAProfiles is invalid. See sf::st_is_valid ## Warning: The shape londonLSOAProfiles_inner is invalid. See sf::st_is_valid #culture_rating_map "],
["regression.html", "Chapter 6 Regression", " Chapter 6 Regression Now we are going to runa regression on #----load all the libraries needed # load in libraries library(tidyverse) library(scales) library(lubridate) library(ggridges) library(gridExtra) #regression library(corrplot) library(rgdal) library(spdep) library(car) #----data visualization packages - https://serialmentor.com/dataviz/geospatial-data.html #install.packages(&quot;remotes&quot;) #install.packages(&quot;devtools&quot;) library(remotes) #install.packages(&quot;cowplot&quot;) #devtools::install_github(&quot;wilkelab/cowplot&quot;) library(cowplot) #install.packages(&quot;colorspace&quot;) library(colorspace) #devtools::install_github(&quot;clauswilke/colorblindr&quot;) #https://rdrr.io/github/clauswilke/dviz.supp/ #devtools::install_github(&quot;clauswilke/dviz.supp&quot;) library(dviz.supp) #https://cran.r-project.org/web/packages/jtools/vignettes/summ.html #install.packages(&#39;jtools&#39;) library(jtools) options(scipen = 999) #londonLSOAProfiles_inner &lt;- londonLSOAProfiles[londonLSOAProfiles$&#39;InnerOuter&#39; == &quot;Inner London&quot;] #londonLSOAProfiles_inner &lt;- subset(londonLSOAProfiles, InnerOuter == &quot;Inner London&quot;) #first, let&#39;s make sure R is reading our InnerOuter variable as a factor londonLSOAProfiles$InnerOuter &lt;- as.factor(londonLSOAProfiles$InnerOuter) #---SUPPLY SIDE MODEL model_freq &lt;- lm(log(`airbnb_freq`) ~ `bame_p` + log(`young_p`) + `nonUK` + `education` + `income` + `house_mortg` + `house_price` + log(culture_freq) + #log(culture_rating) + culture_rating_good + culture_reviews_popular + `InnerOuter`, data = londonLSOAProfiles, na.action=na.exclude) #---DEMAND SIDE MODEL model_reviews &lt;- lm(log(`airbnb_no_reviews`) ~ `bame_p` + log(`young_p`) + `nonUK` + `education` + `employees` + log(`income`) + `house_mortg` + `house_price` + log(`culture_freq`) + culture_rating_good + culture_reviews_popular + `InnerOuter`, data = londonLSOAProfiles, na.action=na.exclude) #---AIRBNB PRICE MODEL model_price &lt;- lm(log(`airbnb_price`) ~ `bame_p` + `nonUK` + `education` + `employees` + `income` + `house_mortg` + `house_price` + log(culture_freq) + culture_rating_good + culture_reviews_popular + `InnerOuter`, data = londonLSOAProfiles, na.action=na.exclude) #summary(model_reviews) #summary(model_freq) #summary(model_price) Dudas et al said remove all variables where vif is above 5 print(vif(model_freq)) ## bame_p log(young_p) nonUK ## 4.54 2.69 4.06 ## education income house_mortg ## 4.98 6.79 2.97 ## house_price log(culture_freq) culture_rating_good ## 2.76 2.56 1.04 ## culture_reviews_popular InnerOuter ## 1.10 2.02 print(vif(model_reviews)) ## bame_p log(young_p) nonUK ## 4.89 2.73 4.07 ## education employees log(income) ## 8.06 3.78 8.65 ## house_mortg house_price log(culture_freq) ## 3.85 2.56 2.56 ## culture_rating_good culture_reviews_popular InnerOuter ## 1.05 1.10 2.04 print(vif(model_price)) ## bame_p nonUK education ## 4.81 4.00 6.72 ## employees income house_mortg ## 3.79 6.55 3.50 ## house_price log(culture_freq) culture_rating_good ## 2.80 1.81 1.04 ## culture_reviews_popular InnerOuter ## 1.07 1.93 Run the regression again without the high vif variable and insignificant variables #---SUPPLY SIDE MODEL model_freq &lt;- lm(log(`airbnb_freq`) ~ `bame_p` + log(`young_p`) + `nonUK` + `education` + `house_mortg` + `house_price` + log(culture_freq) + culture_rating_good + `InnerOuter`, data = londonLSOAProfiles, na.action=na.exclude) #---DEMAND SIDE MODEL model_reviews &lt;- lm(log(`airbnb_no_reviews`) ~ `bame_p` + log(`young_p`) + `nonUK` + `employees` + `house_mortg` + `house_price` + log(`culture_freq`) + culture_rating_good + `InnerOuter`, data = londonLSOAProfiles, na.action=na.exclude) #---AIRBNB PRICE MODEL model_price &lt;- lm(log(`airbnb_price`) ~ `bame_p` + `nonUK` + `employees` + `house_mortg` + `house_price` + log(culture_freq) + culture_rating_good + `InnerOuter`, data = londonLSOAProfiles, na.action=na.exclude) #summary(model_reviews) #summary(model_freq) #summary(model_price) print(vif(model_freq)) ## bame_p log(young_p) nonUK education ## 4.49 2.48 4.03 2.62 ## house_mortg house_price log(culture_freq) culture_rating_good ## 2.62 1.79 2.52 1.04 ## InnerOuter ## 2.00 print(vif(model_reviews)) ## bame_p log(young_p) nonUK employees ## 4.31 2.46 3.55 2.33 ## house_mortg house_price log(culture_freq) culture_rating_good ## 3.08 1.77 2.51 1.04 ## InnerOuter ## 1.86 print(vif(model_price)) ## bame_p nonUK employees house_mortg ## 4.30 3.45 2.32 3.08 ## house_price log(culture_freq) culture_rating_good InnerOuter ## 1.72 1.73 1.04 1.75 summ(model_freq) Observations 2213 (2118 missing obs. deleted) Dependent variable log(airbnb_freq) Type OLS linear regression F(9,2203) 1344.96 R² 0.85 Adj. R² 0.85 Est. S.E. t val. p (Intercept) -3.70 0.22 -16.89 0.00 bame_p -0.01 0.00 -5.07 0.00 log(young_p) 0.87 0.03 32.56 0.00 nonUK 0.01 0.00 5.31 0.00 education 0.02 0.00 13.25 0.00 house_mortg -0.03 0.00 -13.61 0.00 house_price 0.00 0.00 0.85 0.40 log(culture_freq) 0.22 0.02 10.52 0.00 culture_rating_good 0.13 0.04 3.34 0.00 InnerOuterOuter London -0.83 0.04 -19.54 0.00 Standard errors: OLS summ(model_reviews) Observations 2213 (2118 missing obs. deleted) Dependent variable log(airbnb_no_reviews) Type OLS linear regression F(9,2203) 717.61 R² 0.75 Adj. R² 0.74 Est. S.E. t val. p (Intercept) -3.20 0.41 -7.83 0.00 bame_p -0.02 0.00 -7.10 0.00 log(young_p) 0.93 0.04 21.45 0.00 nonUK 0.03 0.00 8.32 0.00 employees 0.03 0.00 6.90 0.00 house_mortg -0.04 0.00 -10.33 0.00 house_price 0.00 0.00 2.75 0.01 log(culture_freq) 0.30 0.03 8.72 0.00 culture_rating_good 0.20 0.06 3.15 0.00 InnerOuterOuter London -1.23 0.07 -18.24 0.00 Standard errors: OLS summ(model_price) Observations 2213 (2118 missing obs. deleted) Dependent variable log(airbnb_price) Type OLS linear regression F(8,2204) 233.02 R² 0.46 Adj. R² 0.46 Est. S.E. t val. p (Intercept) 3.86 0.08 46.64 0.00 bame_p -0.01 0.00 -10.34 0.00 nonUK 0.01 0.00 7.38 0.00 employees 0.00 0.00 4.30 0.00 house_mortg -0.01 0.00 -6.29 0.00 house_price 0.00 0.00 9.93 0.00 log(culture_freq) 0.05 0.01 6.49 0.00 culture_rating_good 0.07 0.02 3.72 0.00 InnerOuterOuter London -0.18 0.02 -9.61 0.00 Standard errors: OLS # #effect_plot(model_freq, data = londonLSOAProfiles, pred = culture_rating, interval = TRUE, plot.points = TRUE) # # #plot_summs(model_freq, model_reviews, scale = TRUE) # # #install.packages(&#39;huxtable&#39;) # library(huxtable) # # export_summs(model_freq) #and for future use, write the residuals out to a column in your dataframe londonLSOAProfiles$model_freq_resids &lt;- residuals(model_freq) londonLSOAProfiles$model_reviews_resids &lt;- residuals(model_reviews) londonLSOAProfiles$model_price_resids &lt;- residuals(model_price) # #https://stackoverflow.com/questions/6882709/how-do-i-deal-with-nas-in-residuals-in-a-regression-in-r # #how to deal with residuals with NA - make use of the row names associated with the data frame provided as input to lm model_freq_resids_graph &lt;- londonLSOAProfiles %&gt;% drop_na(model_freq_resids) %&gt;% ggplot(aes(x= model_freq_resids)) + geom_histogram(alpha = 0.5, fill = &quot;#5EB296&quot;, colour = &quot;#4D4D4D&quot;) + scale_y_continuous(labels = comma) + ggtitle(&quot;RESIDUAL DISTRUBUTION&quot;, subtitle = &quot;Residual distrubution of the Airbnb Price model&quot;) + labs(x= &quot;log(Airbnb Freq)&quot;, y= &quot;Count&quot;) model_reviews_resids_graph &lt;- londonLSOAProfiles %&gt;% drop_na(model_reviews_resids) %&gt;% ggplot(aes(x= model_reviews_resids)) + geom_histogram(alpha = 0.5, fill = &quot;#5EB296&quot;, colour = &quot;#4D4D4D&quot;) + scale_y_continuous(labels = comma) + ggtitle(&quot;RESIDUAL DISTRUBUTION&quot;, subtitle = &quot;Residual distrubution of the Airbnb Price model&quot;) + labs(x= &quot;log(Airbnb Freq)&quot;, y= &quot;Count&quot;) model_price_resids_graph &lt;- londonLSOAProfiles %&gt;% drop_na(model_price_resids) %&gt;% ggplot(aes(x= model_price_resids)) + geom_histogram(alpha = 0.5, fill = &quot;#5EB296&quot;, colour = &quot;#4D4D4D&quot;) + scale_y_continuous(labels = comma) + ggtitle(&quot;RESIDUAL DISTRUBUTION&quot;, subtitle = &quot;Residual distrubution of the Airbnb Price model&quot;) + labs(x= &quot;log(Airbnb Freq)&quot;, y= &quot;Count&quot;) g &lt;- grid.arrange(model_freq_resids_graph, model_reviews_resids_graph, model_price_resids_graph, ncol=3) #plot(model_freq) #nona &lt;- londonLSOAProfiles[londonLSOAProfiles$model_freq_resids != 0] #run durbin-watson test print(durbinWatsonTest(model_freq$residuals)) ## [1] 1.5 print(durbinWatsonTest(model_reviews$residuals)) ## [1] 1.58 print(durbinWatsonTest(model_price$residuals)) ## [1] 1.73 #plot the residuals to see for spatial autocorrelation tm_shape(londonLSOAProfiles) + tm_borders(col = &#39;dimgray&#39;, lwd = 0.3, lty = &quot;solid&quot;) + tm_polygons(&quot;model_freq_resids&quot;, palette = &quot;RdYlBu&quot;) ## Warning: The shape londonLSOAProfiles is invalid. See sf::st_is_valid ## Warning: One tm layer group has duplicated layer types, which are omitted. To ## draw multiple layers of the same type, use multiple layer groups (i.e. specify ## tm_shape prior to each of them). #use Moran&#39;s I to test for spatial auto correlation model_freq_resids_noNA &lt;- londonLSOAProfiles %&gt;% drop_na(model_freq_resids) #Firstly convert our SF object into an SP object: model_freq_resids_SP &lt;- as(model_freq_resids_noNA, &quot;Spatial&quot;) #and calculate the centroids of all LSOAS in London coordsW &lt;- coordinates(model_freq_resids_SP) plot(coordsW) #Now we need to generate a spatial weights matrix (remember from the lecture a couple of weeks ago). We&#39;ll start with a simple binary matrix of queen&#39;s case neighbours #or nearest neighbours knn_wards &lt;- knearneigh(coordsW, k=4) LWard_knn &lt;- knn2nb(knn_wards) plot(LWard_knn, coordinates(coordsW), col=&quot;blue&quot;) #create a spatial weights matrix object from these weights Lward.knn_4_weight &lt;- nb2listw(LWard_knn, style=&quot;C&quot;, zero.policy=TRUE) #now run a moran&#39;s I test on the residuals moran.test(model_freq_resids_SP@data$model_freq_resids, Lward.knn_4_weight, zero.policy=T) ## ## Moran I test under randomisation ## ## data: model_freq_resids_SP@data$model_freq_resids ## weights: Lward.knn_4_weight ## ## Moran I statistic standard deviate = 22, p-value &lt;2e-16 ## alternative hypothesis: greater ## sample estimates: ## Moran I statistic Expectation Variance ## 0.315132 -0.000452 0.000202 #Dealing with Spatially Autocorrelated Residuals - Spatial Lag and Spatial Error models library(spatialreg) # #run a spatially-lagged regression model # slag_dv_model_price_knn4 &lt;- lagsarlm(log(`airbnb_price`) ~ # `young_p` + # `bame_p` + # `nonUK` + # `education` + # `employees` + # `income` + # #`housing` + # `house_mortg` + # `house_price` + # #`transport` + # `culture_freq` + # `culture_rating`+ # `InnerOuter`, # data = r, cache = TRUE, message=FALSE, error=TRUE, # na.action=na.exclude, # nb2listw(LWard_knn, style=&quot;C&quot;), # method = &quot;eigen&quot;) #---SUPPLY SIDE MODEL slag_dv_model_freq_knn4 &lt;- lagsarlm(log(`airbnb_freq`) ~ `bame_p` + log(`young_p`) + `nonUK` + `education` + `house_mortg` + `house_price` + log(culture_freq) + culture_rating_good + `InnerOuter`, data = model_freq_resids_SP, na.action=na.exclude, nb2listw(LWard_knn, style=&quot;C&quot;), method = &quot;eigen&quot;) # # #---DEMAND SIDE MODEL # slag_dv_model_reviews_knn4 &lt;- lagsarlm(log(`airbnb_no_reviews`) ~ # `bame_p` + # log(`young_p`) + # `nonUK` + # `employees` + # `house_mortg` + # `house_price` + # log(`culture_freq`) + # culture_rating_good + # `InnerOuter`, # data = londonLSOAProfiles, na.action=na.exclude, nb2listw(LWard_knn, style=&quot;C&quot;), method = &quot;eigen&quot;) # # #---AIRBNB PRICE MODEL # slag_dv_model_price_knn4 &lt;- lagsarlm(log(`airbnb_price`) ~ # `bame_p` + # `nonUK` + # `employees` + # `house_mortg` + # `house_price` + # log(culture_freq) + # culture_rating_good + # `InnerOuter`, # data = londonLSOAProfiles, na.action=na.exclude, nb2listw(LWard_knn, style=&quot;C&quot;), method = &quot;eigen&quot;) #what do the outputs show? #options(digits = 2) summary(slag_dv_model_freq_knn4) ## ## Call:lagsarlm(formula = log(airbnb_freq) ~ bame_p + log(young_p) + ## nonUK + education + house_mortg + house_price + log(culture_freq) + ## culture_rating_good + InnerOuter, data = model_freq_resids_SP, ## listw = nb2listw(LWard_knn, style = &quot;C&quot;), na.action = na.exclude, ## method = &quot;eigen&quot;) ## ## Residuals: ## Min 1Q Median 3Q Max ## -2.56718 -0.32726 0.03281 0.34933 2.10021 ## ## Type: lag ## Coefficients: (asymptotic standard errors) ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -3.8647e+00 1.7617e-01 -21.9377 &lt; 2.2e-16 ## bame_p -6.5774e-03 1.3908e-03 -4.7290 2.256e-06 ## log(young_p) 6.5594e-01 2.2635e-02 28.9790 &lt; 2.2e-16 ## nonUK 7.1146e-03 1.8829e-03 3.7786 0.0001577 ## education 9.4630e-03 1.3735e-03 6.8897 5.591e-12 ## house_mortg -1.0351e-02 1.8525e-03 -5.5876 2.302e-08 ## house_price -6.6579e-08 4.1486e-08 -1.6048 0.1085302 ## log(culture_freq) 1.4033e-01 1.6886e-02 8.3102 &lt; 2.2e-16 ## culture_rating_good 6.6976e-02 3.1723e-02 2.1113 0.0347505 ## InnerOuterOuter London -2.7503e-01 3.8473e-02 -7.1486 8.769e-13 ## ## Rho: 0.506, LR test value: 823, p-value: &lt; 2.22e-16 ## Asymptotic standard error: 0.0154 ## z-value: 33, p-value: &lt; 2.22e-16 ## Wald statistic: 1087, p-value: &lt; 2.22e-16 ## ## Log likelihood: -1940 for lag model ## ML residual variance (sigma squared): 0.318, (sigma: 0.564) ## Number of observations: 2213 ## Number of parameters estimated: 12 ## AIC: 3905, (AIC for lm: 4726) ## LM test for residual autocorrelation ## test value: 5.71, p-value: 0.016878 #write out the residuals model_freq_resids_SP@data$slag_dv_model_freq_knn4_resids &lt;- slag_dv_model_freq_knn4$residuals #now test for spatial autocorrelation moran.test(model_freq_resids_SP@data$slag_dv_model_freq_knn4_resids, Lward.knn_4_weight) ## ## Moran I test under randomisation ## ## data: model_freq_resids_SP@data$slag_dv_model_freq_knn4_resids ## weights: Lward.knn_4_weight ## ## Moran I statistic standard deviate = -2, p-value = 1 ## alternative hypothesis: greater ## sample estimates: ## Moran I statistic Expectation Variance ## -0.025299 -0.000452 0.000202 # sem_model1 &lt;- errorsarlm(log(`airbnb_price`) ~ # `young_p` + # `bame_p` + # `nonUK` + # `education` + # `employees` + # `income` + # #`housing` + # `house_mortg` + # `house_price` + # #`transport` + # `culture_freq` + # `culture_rating`+ # `InnerOuter`, # data = r, cache = TRUE, message=FALSE, error=TRUE, # na.action=na.exclude, # nb2listw(LWard_knn, style=&quot;C&quot;), # method = &quot;eigen&quot;) #---SUPPLY SIDE MODEL sem_model_freq &lt;- errorsarlm(log(`airbnb_freq`) ~ `bame_p` + log(`young_p`) + `nonUK` + `education` + `house_mortg` + `house_price` + log(culture_freq) + culture_rating_good + `InnerOuter`, data = model_freq_resids_SP, na.action=na.exclude, nb2listw(LWard_knn, style=&quot;C&quot;), method = &quot;eigen&quot;) summary(sem_model_freq) ## ## Call:errorsarlm(formula = log(airbnb_freq) ~ bame_p + log(young_p) + ## nonUK + education + house_mortg + house_price + log(culture_freq) + ## culture_rating_good + InnerOuter, data = model_freq_resids_SP, ## listw = nb2listw(LWard_knn, style = &quot;C&quot;), na.action = na.exclude, ## method = &quot;eigen&quot;) ## ## Residuals: ## Min 1Q Median 3Q Max ## -2.676039 -0.318667 0.051536 0.381209 2.243631 ## ## Type: error ## Coefficients: (asymptotic standard errors) ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -2.7745e+00 2.2412e-01 -12.3796 &lt; 2.2e-16 ## bame_p -8.1577e-03 2.1570e-03 -3.7821 0.0001555 ## log(young_p) 7.6456e-01 2.4821e-02 30.8032 &lt; 2.2e-16 ## nonUK 1.5620e-02 2.7804e-03 5.6180 1.932e-08 ## education 1.5775e-02 1.9643e-03 8.0308 8.882e-16 ## house_mortg -1.4264e-02 2.2348e-03 -6.3828 1.739e-10 ## house_price -1.6738e-08 5.3372e-08 -0.3136 0.7538149 ## log(culture_freq) 1.3114e-01 1.8897e-02 6.9400 3.922e-12 ## culture_rating_good 3.2871e-02 3.1798e-02 1.0337 0.3012610 ## InnerOuterOuter London -9.5427e-01 6.5359e-02 -14.6006 &lt; 2.2e-16 ## ## Lambda: 0.625, LR test value: 510, p-value: &lt; 2.22e-16 ## Asymptotic standard error: 0.0185 ## z-value: 33.7, p-value: &lt; 2.22e-16 ## Wald statistic: 1137, p-value: &lt; 2.22e-16 ## ## Log likelihood: -2097 for error model ## ML residual variance (sigma squared): 0.352, (sigma: 0.593) ## Number of observations: 2213 ## Number of parameters estimated: 12 ## AIC: 4218, (AIC for lm: 4726) library(spgwr) #calculate kernel bandwidth GWRbandwidth &lt;- gwr.sel(log(`airbnb_freq`) ~ `bame_p` + log(`young_p`) + `nonUK` + `education` + `house_mortg` + `house_price` + log(culture_freq) + culture_rating_good + `InnerOuter`, data = model_freq_resids_SP, coords=coordsW, adapt=T) ## Warning in gwr.sel(log(airbnb_freq) ~ bame_p + log(young_p) + nonUK + education ## + : data is Spatial* object, ignoring coords argument ## Adaptive q: 0.382 CV score: 1048 ## Adaptive q: 0.618 CV score: 1069 ## Adaptive q: 0.236 CV score: 1024 ## Adaptive q: 0.146 CV score: 992 ## Adaptive q: 0.0902 CV score: 948 ## Adaptive q: 0.0557 CV score: 894 ## Adaptive q: 0.0344 CV score: 837 ## Adaptive q: 0.0213 CV score: 795 ## Adaptive q: 0.0132 CV score: 776 ## Adaptive q: 0.00813 CV score: 775 ## Adaptive q: 0.00998 CV score: 773 ## Adaptive q: 0.0103 CV score: 773 ## Adaptive q: 0.0096 CV score: 773 ## Adaptive q: 0.00975 CV score: 773 ## Adaptive q: 0.0098 CV score: 773 ## Adaptive q: 0.00971 CV score: 773 ## Adaptive q: 0.00975 CV score: 773 #run the gwr model gwr.model = gwr(log(`airbnb_freq`) ~ `bame_p` + log(`young_p`) + `nonUK` + `education` + `house_mortg` + `house_price` + log(culture_freq) + culture_rating_good + `InnerOuter`, data = model_freq_resids_SP, coords=coordsW, adapt=GWRbandwidth, hatmatrix=TRUE, se.fit=TRUE) ## Warning in gwr(log(airbnb_freq) ~ bame_p + log(young_p) + nonUK + education + : ## data is Spatial* object, ignoring coords argument #print the results of the model gwr.model ## Call: ## gwr(formula = log(airbnb_freq) ~ bame_p + log(young_p) + nonUK + ## education + house_mortg + house_price + log(culture_freq) + ## culture_rating_good + InnerOuter, data = model_freq_resids_SP, ## coords = coordsW, adapt = GWRbandwidth, hatmatrix = TRUE, ## se.fit = TRUE) ## Kernel function: gwr.Gauss ## Adaptive quantile: 0.00975 (about 21 of 2213 data points) ## Summary of GWR coefficient estimates at data points: ## Min. 1st Qu. Median 3rd Qu. Max. Global ## X.Intercept. -7.23e+00 -4.32e+00 -3.36e+00 -2.17e+00 1.36e+00 -3.70 ## bame_p -5.66e-02 -2.04e-02 -9.49e-03 5.62e-04 2.86e-02 -0.01 ## log.young_p. 4.42e-01 6.66e-01 7.64e-01 8.75e-01 1.11e+00 0.87 ## nonUK -2.72e-02 1.29e-02 2.19e-02 3.22e-02 7.71e-02 0.01 ## education -1.64e-02 4.47e-03 1.57e-02 2.71e-02 7.34e-02 0.02 ## house_mortg -5.83e-02 -2.21e-02 -1.20e-02 -4.04e-03 3.95e-02 -0.03 ## house_price -4.55e-06 -1.37e-07 1.43e-07 5.24e-07 5.62e-06 0.00 ## log.culture_freq. -1.80e-01 6.66e-02 1.17e-01 1.82e-01 5.13e-01 0.22 ## culture_rating_good -4.56e-01 -5.28e-02 4.13e-02 1.58e-01 7.38e-01 0.13 ## InnerOuterOuter.London -1.94e+00 -7.92e-01 -5.25e-01 -3.46e-01 6.10e-01 -0.83 ## Number of data points: 2213 ## Effective number of parameters (residual: 2traceS - traceS&#39;S): 517 ## Effective degrees of freedom (residual: 2traceS - traceS&#39;S): 1696 ## Sigma (residual: 2traceS - traceS&#39;S): 0.557 ## Effective number of parameters (model: traceS): 368 ## Effective degrees of freedom (model: traceS): 1845 ## Sigma (model: traceS): 0.534 ## Sigma (ML): 0.488 ## AICc (GWR p. 61, eq 2.33; p. 96, eq. 4.21): 3991 ## AIC (GWR p. 96, eq. 4.22): 3472 ## Residual sum of squares: 527 ## Quasi-global R2: 0.925 results&lt;-as.data.frame(gwr.model$SDF) names(results) ## [1] &quot;sum.w&quot; &quot;X.Intercept.&quot; ## [3] &quot;bame_p&quot; &quot;log.young_p.&quot; ## [5] &quot;nonUK&quot; &quot;education&quot; ## [7] &quot;house_mortg&quot; &quot;house_price&quot; ## [9] &quot;log.culture_freq.&quot; &quot;culture_rating_good&quot; ## [11] &quot;InnerOuterOuter.London&quot; &quot;X.Intercept._se&quot; ## [13] &quot;bame_p_se&quot; &quot;log.young_p._se&quot; ## [15] &quot;nonUK_se&quot; &quot;education_se&quot; ## [17] &quot;house_mortg_se&quot; &quot;house_price_se&quot; ## [19] &quot;log.culture_freq._se&quot; &quot;culture_rating_good_se&quot; ## [21] &quot;InnerOuterOuter.London_se&quot; &quot;gwr.e&quot; ## [23] &quot;pred&quot; &quot;pred.se&quot; ## [25] &quot;localR2&quot; &quot;X.Intercept._se_EDF&quot; ## [27] &quot;bame_p_se_EDF&quot; &quot;log.young_p._se_EDF&quot; ## [29] &quot;nonUK_se_EDF&quot; &quot;education_se_EDF&quot; ## [31] &quot;house_mortg_se_EDF&quot; &quot;house_price_se_EDF&quot; ## [33] &quot;log.culture_freq._se_EDF&quot; &quot;culture_rating_good_se_EDF&quot; ## [35] &quot;InnerOuterOuter.London_se_EDF&quot; &quot;pred.se.1&quot; #attach coefficients to original dataframe model_freq_resids_SP@data$coefCultureFreq &lt;- results$log.culture_freq. model_freq_resids_SP@data$coefCultureRatingGood &lt;- results$culture_rating_good #model_freq_resids_SP@data$coefCultureRating &lt;- results$culture_rating_se # # model_freq_resids_SP@data$coefPrivateRent &lt;- results$X.Tenure..2011..Private.rented..... # # model_freq_resids_SP@data$coefCrime &lt;- results$X.Crime..numbers..Violence.Against.The.Person.2012.13. # # model_freq_resids_SPdata$coefLev4Qual &lt;- results$X.Qualifications..2011..Highest.level.of.qualification..Level.4.qualifications.and.above.. tm_shape(model_freq_resids_SP) + tm_polygons(col = &quot;coefCultureFreq&quot;, palette = &quot;RdBu&quot;) ## Warning: The shape model_freq_resids_SP is invalid. See sf::st_is_valid tm_shape(model_freq_resids_SP) + tm_polygons(col = &quot;coefCultureRatingGood&quot;, palette = &quot;RdBu&quot;) ## Warning: The shape model_freq_resids_SP is invalid. See sf::st_is_valid # #run a final OLS model # model_house_price &lt;- lm(log(`house_price`) ~ # `bame_p` + # `nonUK` + # `education` + # `employees` + # `income` + # `house_mortg` + # `house_price` + # log(culture_freq) + # `InnerOuter`, # data = londonLSOAProfiles, na.action=na.exclude) # # summary(model_house_price) "],
["references.html", "References", " References "]
]
